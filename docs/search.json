[{"path":"https://jonathonchow.github.io/AwesomePackage/articles/05_theory_em.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Models and Methods I: Fit PSD Model by EM Algorithm","text":"  use Expectation-Maximization algorithm (EM) fit PSD model (Tang et al. 2005).","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/05_theory_em.html","id":"psd-model","dir":"Articles","previous_headings":"","what":"PSD Model","title":"Models and Methods I: Fit PSD Model by EM Algorithm","text":"  typical data set consists genotypes large number \\(J\\) single nucleotide polymorphisms (SNPs) large number \\(\\) unrelated individuals. individuals drawn admixed population contributions \\(K\\) postulated ancestral populations. Population \\(k\\) contributes fraction \\(p_{ik}\\) individual \\(\\)’s genome. Note \\(\\sum_{k=1}^Kp_{ik}=1\\), \\(p_{ik}\\geq 0\\). Allele 1 SNP \\(j\\) frequency \\(f_{kj}\\) population \\(k\\). Note \\(0\\leq f_{kj}\\leq 1\\). matter convention, one can choose allele 1 minor allele alternative allele 2 major allele. model, \\(p_{ik}\\) \\(f_{kj}\\) unknown. primarily interested estimating \\(p_{ik}\\) control ancestry association study, approach also yields estimates \\(f_{kj}\\).   Let \\((g_{ij}^1,g_{ij}^2)\\) represents genotype marker \\(j\\) person \\(\\), \\(g_{ij}^\\) represent observed number copies allele 1 seat \\(\\). Thus, \\((g_{ij}^1,g_{ij}^2)\\) equals \\((1,1)\\), \\((1,0)\\), \\((0,1)\\), \\((0,0)\\) accordingly, \\(\\) genotype 1/1, 1/2, 2/1, 2/2 marker \\(j\\).   Note individuals formed random union gametes. produces binomial proportions \\[P(g_{ij}^=1)=\\sum_{k=1}^Kp_{ik}f_{kj},\\quad P(g_{ij}^=0)=\\sum_{k=1}^Kp_{ik}(1-f_{kj}),\\quad =1,2.\\] Since individuals \\(\\), SNPs \\(j\\), seats \\(\\) considered independent, log-likelihood entire sample \\[\\mathcal{L}(G|P,F)=\\sum_{=1}^\\sum_{j=1}^J\\sum_{=1}^2\\bigg\\{g_{ij}^alog\\Big[\\sum_{k=1}^Kp_{ik}f_{kj}\\Big]+(1-g_{ij}^)log\\Big[\\sum_{k=1}^Kp_{ik}(1-f_{kj})\\Big]\\bigg\\}\\] additive constant enter maximization problem. Let \\(g_{ij}=g_{ij}^1+g_{ij}^2\\). log-likelihood can also expressed \\[\\mathcal{L}(G|P,F)=\\sum_{=1}^\\sum_{j=1}^J\\bigg\\{g_{ij}log\\Big[\\sum_{k=1}^Kp_{ik}f_{kj}\\Big]+(2-g_{ij})log\\Big[\\sum_{k=1}^Kp_{ik}(1-f_{kj})\\Big]\\bigg\\}.\\] parameter matrices \\(P=\\{p_{ik}\\}\\) \\(F=\\{f_{kj}\\}\\) dimensions \\(\\times K\\) \\(K\\times J\\), total \\(K(+J)\\) parameters.   Note log-likelihood invariant permutations labels ancestral populations. Thus, log-likelihood least \\(K!\\) equivalent global maxima. practice, minor nuisance affect convergence well-behaved algorithms. constraints \\(0\\leq f_{kj}\\leq 1\\), \\(p_{ik}\\geq 0\\), \\(\\sum_{k=1}^Kp_{ik}=1\\) significant hindrances contriving good optimization algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/05_theory_em.html","id":"expectation-maximization-algorithm","dir":"Articles","previous_headings":"","what":"Expectation-Maximization Algorithm","title":"Models and Methods I: Fit PSD Model by EM Algorithm","text":"  goal solve MLE problem observed variable \\(x\\) \\[\\theta_{MLE}=\\mathop{argmax}\\limits_{\\theta}log P(x|\\theta).\\] However, probabilistic model contains observed variable \\(x\\) latent variable \\(z\\), MLE often find analytical solution directly. EM algorithm provides way solve MLE iteratively (Bishop Nasrabadi 2006).   first thing notice \\[log P(x|\\theta) = log P(x,z|\\theta)-log P(z|x,\\theta) = log \\frac{P(x,z|\\theta)}{Q(z)} - log \\frac{P(x|z,\\theta)}{Q(z)},\\] \\(Q(z)\\) undetermined distribution.   take expectation sides equation, \\[\\mathbb{E}_{Q(z)} \\Big[LHS\\Big] = \\int_{z}log P(x|\\theta)Q(z)dz = log P(x|\\theta)\\int_{z}Q(z)dz = log P(x|\\theta),\\] \\[\\mathbb{E}_{Q(z)} \\Big[RHS\\Big] = \\int_{z}log \\frac{P(x,z|\\theta)}{Q(z)}Q(z)dz - \\int_{z}log \\frac{P(x|z,\\theta)}{Q(z)}Q(z)dz := \\mathcal{L}(Q(z),\\theta) + KL(Q(z)\\|P(z|x,\\theta)).\\] Hence, \\[log P(x|\\theta)=\\mathcal{L}(Q(z),\\theta) + KL(Q(z)\\|P(z|x,\\theta)).\\]   use property KL divergence \\(KL(Q\\|P)\\geq 0\\), equality holds \\(Q=P\\). Thus, \\[log P(x|\\theta)\\geq \\mathcal{L}(Q(z),\\theta),\\] Therefore, also refer \\(\\mathcal{L}(Q(z),\\theta)\\) evidence lower bound (ELBO).   condition \\(\\)th iteration, first fix parameter \\(\\theta^{()}\\), take \\(Q(z)=P(z|x,\\theta)\\), \\(log P(x|\\theta^{()})=\\mathcal{L}(Q(z),\\theta)\\), E-step. Next, change parameter \\(\\theta\\), maximize ELBO, get parameter \\(\\theta^{(+1)}\\) \\((+1)\\)th iteration, M-step. Finally, simplification can carried obtain EM algorithm.   precisely, \\[\\begin{split} &\\theta^{(+1)}\\\\ =& \\mathop{argmax}\\limits_{\\theta}\\mathcal{L}(Q(z),\\theta) \\\\ =& \\mathop{argmax}\\limits_{\\theta}\\int_{z}log \\frac{P(x,z|\\theta)}{Q(z)}Q(z)dz \\\\ =& \\mathop{argmax}\\limits_{\\theta}\\int_{z}log \\frac{P(x,z|\\theta)}{P(z|x,\\theta^{()})}P(z|x,\\theta^{()})dz \\\\ =& \\mathop{argmax}\\limits_{\\theta}\\int_{z}log P(x,z|\\theta)P(z|x,\\theta^{()})dz - \\int_{z}log P(z|x,\\theta^{()})P(z|x,\\theta^{()})dz \\\\ =& \\mathop{argmax}\\limits_{\\theta}\\int_{z}log P(x,z|\\theta)P(z|x,\\theta^{()})dz \\\\ =& \\mathbb{E}_{P(z|x,\\theta^{()})}\\Big[log P(x,z|\\theta)\\Big]. \\end{split}\\]   conclusion, E-step, compute expectation \\[\\mathbb{E}_{P(z|x,\\theta^{()})}\\Big[log P(x,z|\\theta)\\Big]=\\int_{z}log P(x,z|\\theta)P(z|x,\\theta^{()})dz,\\] M-step, compute maximization update parameters \\[\\theta^{(+1)}=\\mathop{argmax}\\limits_{\\theta}\\mathbb{E}_{P(z|x,\\theta^{()})}\\Big[log P(x,z|\\theta)\\Big],\\] log-likelihood incomplete data converges. EM algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/05_theory_em.html","id":"fit-psd-model-by-em-algorithm","dir":"Articles","previous_headings":"","what":"Fit PSD Model by EM Algorithm","title":"Models and Methods I: Fit PSD Model by EM Algorithm","text":"  derive EM algorithm PSD model. observed variable \\(G=\\{(g_{ij}^1,g_{ij}^2)\\}_{\\times J}\\). model parameters \\(P=\\{p_{ik}\\}_{\\times K}\\) \\(F=\\{f_{kj}\\}_{K\\times J}\\). latent variable \\(Z=\\{z_{ij}^1,z_{ij}^2\\}_{\\times J}\\), \\(z_{ij}^\\) element set \\(\\{1,\\ldots,K\\}\\), denotes population genes individual \\(\\) marker \\(j\\) position \\(\\) really come.   Consider log-likelihood complete data \\[\\begin{split} &log P(G,Z|P,F)\\\\ =&log P(G|Z,P,F) + log P(Z|P,F) \\\\ =&\\sum_{=1}^\\sum_{j=1}^J\\sum_{k=1}^K\\sum_{=1}^2\\bigg\\{\\textbf{1}(z_{ij}^=k)\\Big[g_{ij}^alogf_{kj}+(1-g_{ij}^)log(1-f_{kj})\\Big]+\\textbf{1}(z_{ij}^=k)logp_{ik}\\bigg\\}. \\end{split}\\]   E-step. Using linear property expectations, expectation \\(t\\)th iteration \\[\\begin{split} &\\mathbb{E}_{P(Z|G,P^{(t)},F^{(t)})}\\Big[log P(G,Z|P,F)\\Big]\\\\=&\\sum_{=1}^\\sum_{j=1}^J\\sum_{k=1}^K\\sum_{=1}^2\\bigg\\{P(z_{ij}^=k|G,P^{(t)},F^{(t)})\\Big[g_{ij}^alogf_{kj}+(1-g_{ij}^)log(1-f_{kj})+logp_{ik}\\Big]\\bigg\\}. \\end{split}\\] Using Bayesian formula, \\[\\begin{split} &P(z_{ij}^=k|G,P^{(t)},F^{(t)})\\\\ =& P(z_{ij}^=k|g_{ij}^,p_{ik}^{(t)},f_{kj}^{(t)})\\\\ =& \\frac{P(g_{ij}^|z_{ij}^=k,p_{ik}^{(t)},f_{kj}^{(t)})P(z_{ij}^=k|p_{ik}^{(t)},f_{kj}^{(t)})}{\\sum_{k=1}^KP(g_{ij}^|z_{ij}^=k,p_{ik}^{(t)},f_{kj}^{(t)})P(z_{ij}^=k|p_{ik}^{(t)},f_{kj}^{(t)})}\\\\ =& \\frac{p_{ik}^{(t)}(f_{kj}^{(t)})^{g_{ij}^}(1-f_{kj}^{(t)})^{(1-g_{ij}^)}}{\\sum_{k=1}^Kp_{ik}^{(t)}(f_{kj}^{(t)})^{g_{ij}^}(1-f_{kj}^{(t)})^{(1-g_{ij}^)}}.\\end{split}\\]   Next, note \\[p_{ik}^{(t)}(f_{kj}^{(t)})^{g_{ij}^}(1-f_{kj}^{(t)})^{(1-g_{ij}^)}= \\left\\{ \\begin{aligned} &p_{ik}^{(t)}f_{kj}^{(t)},&\\quad &g_{ij}^=1\\\\ &p_{ik}^{(t)}(1-f_{kj}^{(t)}),&\\quad &g_{ij}^=0. \\end{aligned} \\right. \\] Thus, \\[ P(z_{ij}^=k|G,P^{(t)},F^{(t)})= \\left\\{ \\begin{aligned} &\\frac{p_{ik}^{(t)}f_{kj}^{(t)}}{\\sum_{k=1}^Kp_{ik}^{(t)}f_{kj}^{(t)}}:=a_{ijk}^{(t)},&\\quad &g_{ij}^=1\\\\ &\\frac{p_{ik}^{(t)}(1-f_{kj}^{(t)})}{\\sum_{k=1}^Kp_{ik}^{(t)}(1-f_{kj}^{(t)})}:=b_{ijk}^{(t)},&\\quad &g_{ij}^=0. \\end{aligned} \\right. \\]   M-step. Calculate parameters \\((t+1)\\)th iteration. problem transformed solving optimization problem \\[\\begin{split} \\mathop{max}\\limits_{P,F} & \\quad \\mathbb{E}_{P(Z|G,P^{(t)},F^{(t)})}\\Big[log P(G,Z|P,F)\\Big]\\\\ s.t. & \\quad \\sum_{k=1}^Kp_{ik}=1,\\quad =1,\\ldots,. \\end{split}\\] Using Lagrange multiplier method, define \\(\\mathcal{L}\\) \\[\\mathcal{L} = \\mathbb{E}_{P(Z|G,P^{(t)},F^{(t)})}\\Big[log P(G,Z|P,F)\\Big] + \\sum_{=1}^\\tau_i\\Big(1-\\sum_{k=1}^Kp_{ik}\\Big).\\] Take partial derivatives \\(p_{ik}\\) \\(f_{kj}\\) set equal zero \\[\\frac{1}{p_{ik}}\\sum_{j=1}^J\\sum_{=1}^2P(z_{ij}^=k|G,P^{(t)},F^{(t)})-\\tau_i=0,\\quad =1,\\ldots,,\\quad k=1,\\ldots,K,\\] \\[\\sum_{=1}^\\sum_{=1}^2P(z^a_{ij}=k|G,P^{(t)},F^{(t)})\\Big[g_{ij}^\\frac{1}{f_{kj}}+(1-g_{ij}^)\\frac{1}{1-f_{kj}}\\Big]=0,\\quad j=1,\\ldots,J,\\quad k=1,\\ldots,K.\\]   sum first equality k, \\[\\frac{1}{\\tau_i}\\sum_{k=1}^K\\sum_{j=1}^J\\sum_{=1}^2P(z_{ij}^=k|G,P^{(t)},F^{(t)})=\\sum_{k=1}^Kp_{ik}=1,\\quad =1,\\ldots,.\\] Thus, Lagrange multiplier \\[\\tau_i=\\sum_{j=1}^J\\sum_{=1}^2\\sum_{k=1}^KP(z_{ij}^=k|G,P^{(t)},F^{(t)})=\\sum_{j=1}^J\\sum_{=1}^21=2J,\\quad =1,\\ldots,.\\]   Thus, obtain parameter update formula \\((t+1)\\)th iteration \\[\\begin{split} &p_{ik}^{(t+1)}\\\\ =&\\frac{\\sum_{j=1}^J\\sum_{=1}^2g_{ij}^aP(z_{ij}^=k|G,P^{(t)},F^{(t)})+\\sum_{j=1}^J\\sum_{=1}^2(1-g_{ij}^)P(z_{ij}^=k|G,P^{(t)},F^{(t)})}{2J}\\\\ =&\\frac{\\sum_{j=1}^J\\sum_{=1}^2P(z_{ij}^=k|G,P^{(t)},F^{(t)})}{2J},\\quad =1,\\ldots,,\\quad k=1,\\ldots,K, \\end{split}\\] \\[\\begin{split} &f_{kj}^{(t+1)}\\\\ =& \\frac{\\sum_{=1}^\\sum_{=1}^2g_{ij}^aP(z_{ij}^=k|G,P^{(t)},F^{(t)})}{\\sum_{=1}^\\sum_{=1}^2g_{ij}^aP(z_{ij}^=k|G,P^{(t)},F^{(t)})+\\sum_{=1}^\\sum_{=1}^2(1-g_{ij}^)P(z_{ij}^=k|G,P^{(t)},F^{(t)})}\\\\ =&\\frac{\\sum_{=1}^\\sum_{=1}^2g_{ij}^aP(z_{ij}^=k|G,P^{(t)},F^{(t)})}{\\sum_{=1}^\\sum_{=1}^2P(z_{ij}^=k|G,P^{(t)},F^{(t)})},\\quad j=1,\\ldots,J,\\quad k=1,\\ldots,K. \\end{split}\\]   Finally, Using expression \\(P(z_{ij}^=k|G,P^{(t)},F^{(t)})\\), can get \\[\\sum_{=1}^2g_{ij}^aP(z_{ij}^=k|G,P^{(t)},F^{(t)})= \\left\\{ \\begin{aligned} &2a_{ijk}^{(t)},&(g_{ij}^1,g_{ij}^2)=(1,1)\\\\ &a_{ijk}^{(t)},&(g_{ij}^1,g_{ij}^2)=(1,0)\\\\ &a_{ijk}^{(t)},&(g_{ij}^1,g_{ij}^2)=(0,1)\\\\ &0,&(g_{ij}^1,g_{ij}^2)=(0,0) \\end{aligned} \\right. =\\Big(\\sum_{=1}^2g_{ij}^\\Big)a_{ijk}^{(t)}=g_{ij}a_{ijk}^{(t)},\\] \\[\\sum_{=1}^2(1-g_{ij}^)P(z_{ij}^=k|G,P^{(t)},F^{(t)})= \\left\\{ \\begin{aligned} &0,&(g_{ij}^1,g_{ij}^2)=(1,1)\\\\ &b_{ijk}^{(t)},&(g_{ij}^1,g_{ij}^2)=(1,0)\\\\ &b_{ijk}^{(t)},&(g_{ij}^1,g_{ij}^2)=(0,1)\\\\ &2b_{ijk}^{(t)},&(g_{ij}^1,g_{ij}^2)=(0,0) \\end{aligned} \\right. =\\Big[\\sum_{=1}^2(1-g_{ij}^)\\Big]b_{ijk}^{(t)}=(2-g_{ij})b_{ijk}^{(t)}.\\] parameter update formula can written \\[p_{ik}^{(t+1)}=\\frac{\\sum_{j=1}^Jg_{ij}a_{ijk}^{(t)}+\\sum_{j=1}^J(2-g_{ij})b_{ijk}^{(t)}}{2J},\\quad =1,\\ldots,,\\quad k=1,\\ldots,K,\\] \\[f_{kj}^{(t+1)}=\\frac{\\sum_{=1}^Ig_{ij}a_{ijk}^{(t)}}{\\sum_{=1}^Ig_{ij}a_{ijk}^{(t)}+\\sum_{=1}^(2-g_{ij})b_{ijk}^{(t)}},\\quad j=1,\\ldots,J,\\quad k=1,\\ldots,K.\\]   conclusion, E-step, compute expectation \\(a_{ijk}\\) \\(b_{ijk}\\), M-step, compute maximization update parameters \\(p_{ik}\\) \\(f_{kj}\\), log-likelihood incomplete data \\(\\mathcal{L}(G|P,F)\\) converges. EM algorithm PSD model.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/05_theory_em.html","id":"acceleration","dir":"Articles","previous_headings":"","what":"Acceleration","title":"Models and Methods I: Fit PSD Model by EM Algorithm","text":"  can speed EM algorithm two ways. first code level. write core parameter update part C++. second algorithm level, can use SQUAREM accelerate algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/05_theory_em.html","id":"algorithm-implementation","dir":"Articles","previous_headings":"","what":"Algorithm Implementation","title":"Models and Methods I: Fit PSD Model by EM Algorithm","text":"  present implementation EM algorithm R package AwesomePackage. can fit PSD model using EM algorithm using function psd_fit_em. time, can use plot_loss see changes log-likelihood plot_structure plot structure.   example.     See AwesomePackage details.","code":"library(AwesomePackage) G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) result <- psd_fit_em(G, 2, 1e-5, 50) result ## $P ##              [,1]         [,2] ## [1,] 9.999984e-01 1.585739e-06 ## [2,] 1.972075e-15 1.000000e+00 ## [3,] 6.891856e-01 3.108144e-01 ##  ## $F ##              [,1]        [,2]         [,3]      [,4]          [,5] ## [1,] 2.765492e-01 5.82298e-09 5.737395e-01 0.0000000  3.116913e-01 ## [2,] 8.703332e-10 1.00000e+00 4.192058e-27 0.4135047 5.987549e-152 ##  ## $Loss ## [1] -0.7147989 -0.7079605 -0.7074654 -0.7074278 -0.7074249 ##  ## $Iterations ## [1] 50 L <- result$Loss plot_loss(list(L), \"em\", 10) P <- result$P plot_structure(P)"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"use sequential quadratic programming algorithm (SQP) fit PSD model (Alexander, Novembre, Lange 2009).","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"psd-model","dir":"Articles","previous_headings":"","what":"PSD Model","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  typical data set consists genotypes large number \\(J\\) single nucleotide polymorphisms (SNPs) large number \\(\\) unrelated individuals. individuals drawn admixed population contributions \\(K\\) postulated ancestral populations. Population \\(k\\) contributes fraction \\(p_{ik}\\) individual \\(\\)’s genome. Note \\(\\sum_{k=1}^Kp_{ik}=1\\), \\(p_{ik}\\geq 0\\). Allele 1 SNP \\(j\\) frequency \\(f_{kj}\\) population \\(k\\). Note \\(0\\leq f_{kj}\\leq 1\\). matter convention, one can choose allele 1 minor allele alternative allele 2 major allele. model, \\(p_{ik}\\) \\(f_{kj}\\) unknown. primarily interested estimating \\(p_{ik}\\) control ancestry association study, approach also yields estimates \\(f_{kj}\\).   Let \\((g_{ij}^1,g_{ij}^2)\\) represents genotype marker \\(j\\) person \\(\\), \\(g_{ij}^\\) represent observed number copies allele 1 seat \\(\\). Thus, \\((g_{ij}^1,g_{ij}^2)\\) equals \\((1,1)\\), \\((1,0)\\), \\((0,1)\\), \\((0,0)\\) accordingly, \\(\\) genotype 1/1, 1/2, 2/1, 2/2 marker \\(j\\).   Note individuals formed random union gametes. produces binomial proportions \\[P(g_{ij}^=1)=\\sum_{k=1}^Kp_{ik}f_{kj},\\quad P(g_{ij}^=0)=\\sum_{k=1}^Kp_{ik}(1-f_{kj}),\\quad =1,2.\\] Since individuals \\(\\), SNPs \\(j\\), seats \\(\\) considered independent, log-likelihood entire sample \\[\\mathcal{L}(G|P,F)=\\sum_{=1}^\\sum_{j=1}^J\\sum_{=1}^2\\bigg\\{g_{ij}^alog\\Big[\\sum_{k=1}^Kp_{ik}f_{kj}\\Big]+(1-g_{ij}^)log\\Big[\\sum_{k=1}^Kp_{ik}(1-f_{kj})\\Big]\\bigg\\}\\] additive constant enter maximization problem. Let \\(g_{ij}=g_{ij}^1+g_{ij}^2\\). log-likelihood can also expressed \\[\\mathcal{L}(G|P,F)=\\sum_{=1}^\\sum_{j=1}^J\\bigg\\{g_{ij}log\\Big[\\sum_{k=1}^Kp_{ik}f_{kj}\\Big]+(2-g_{ij})log\\Big[\\sum_{k=1}^Kp_{ik}(1-f_{kj})\\Big]\\bigg\\}.\\] parameter matrices \\(P=\\{p_{ik}\\}\\) \\(F=\\{f_{kj}\\}\\) dimensions \\(\\times K\\) \\(K\\times J\\), total \\(K(+J)\\) parameters.   Note log-likelihood invariant permutations labels ancestral populations. Thus, log-likelihood least \\(K!\\) equivalent global maxima. practice, minor nuisance affect convergence well-behaved algorithms. constraints \\(0\\leq f_{kj}\\leq 1\\), \\(p_{ik}\\geq 0\\), \\(\\sum_{k=1}^Kp_{ik}=1\\) significant hindrances contriving good optimization algorithm.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"general-optimization-theory","dir":"Articles","previous_headings":"Quadratic Programming Problem and Active Set Method","what":"General optimization theory","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  consider optimization problem standard form: \\[ \\begin{split} min & \\quad f_0(x) \\\\ s.t. & \\quad f_i(x)\\leq 0,\\quad =1,\\ldots,m \\\\ & \\quad h_i(x)=0,\\quad =1,\\ldots,p, \\end{split} \\] variable \\(x\\\\mathbb{R}^n\\). define \\(\\mathcal{L}\\) \\[\\mathcal{L}(x,\\lambda,\\nu)=f_0(x)+\\sum_{=1}^m\\lambda_if_i(x)+\\sum_{=1}^p\\nu_ih_(x).\\] refer \\(\\lambda_i\\) \\(\\nu_i\\) .   Let \\(x^*\\) \\((\\lambda^*, \\nu^*)\\) primal dual optimal points zero duality gap (strong duality), follows (KKT) conditions \\[ \\begin{split} f_i(x^*)\\leq 0 & ,\\quad =1,\\ldots,m \\\\ h_i(x^*)=0 & ,\\quad =1,\\ldots,p \\\\ \\lambda_i^*\\geq 0 & ,\\quad =1,\\ldots,m \\\\ \\lambda_i^*f_i(x^*)=0 & ,\\quad =1,\\ldots,m \\\\ \\nabla f_0(x^*)+\\sum_{=0}^m\\lambda_i^*\\nabla f_i(x^*)+\\sum_{=1}^p\\nu_i^*\\nabla h_i(x^*)& . \\end{split} \\]   primal problem convex, KKT conditions also sufficient points primal dual optimal.   fundamental property convex optimization problems locally optimal point also (globally) optimal.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"general-linear-constrained-quadratic-programming-problem","dir":"Articles","previous_headings":"Quadratic Programming Problem and Active Set Method","what":"General linear constrained quadratic programming problem","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  consider quadratic programming problems general linear constraints standard form: \\[ \\begin{aligned} min & \\quad \\frac{1}{2}x^TQx+c^Tx \\\\ s.t. & \\quad a_i^Tx-b_i\\leq 0,\\quad \\\\mathcal{}=\\{1,\\ldots,m\\} \\\\ & \\quad a_i^Tx-b_i=0,\\quad \\\\mathcal{E}=\\{m+1,\\ldots,m+l\\}, \\end{aligned} \\quad\\quad(QP) \\] \\(Q\\) positive semidefinite matrix. convex optimization problem. consider case Q indefinite matrix, fact NP-hard problem.   give fundamental theorem active sets. consider following equality constrained quadratic programming problem \\[ \\begin{aligned} min & \\quad \\frac{1}{2}x^TQx+c^Tx \\\\ s.t. & \\quad a_i^Tx-b_i\\leq 0,\\quad \\\\mathcal{}(x^*) \\\\ & \\quad a_i^Tx-b_i=0,\\quad \\\\mathcal{E}, \\end{aligned} \\quad\\quad(QP^*) \\] \\(\\mathcal{}(x^*)=\\{|a_i^Tx^*=b_i,\\\\mathcal{}\\}\\).   \\(x^*\\) optimal solution \\((QP)\\) \\(x^*\\) also optimal solution \\((QP^*)\\). fact, obtained using equivalence optimal solution KKT condition convex optimization problems. geometrically intuitive, use contour map notice constraints convex polyhedra, optimal value can found boundary.   Conversely, \\(x^*\\) feasible solution \\((QP)\\) optimal solution \\((QP^*)\\), corresponding \\(\\lambda_i^*\\) satisfies \\(\\lambda_i^*\\geq0\\), \\(\\\\mathcal{}(x^*)\\), \\(x^*\\) optimal solution \\((QP)\\). fact, obtained using KKT conditions complementary relaxation.   Using fundamental theorem active sets, transform inequality constrained quadratic programming problem finite number equality constrained quadratic programming problems, guaranteed . quadratic programming problem equality constraints can solved easily.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"equality-constrained-quadratic-programming-problem","dir":"Articles","previous_headings":"Quadratic Programming Problem and Active Set Method","what":"Equality constrained quadratic programming problem","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  consider quadratic programming problems equality constraints standard form: \\[ \\begin{aligned} min & \\quad \\frac{1}{2}x^TQx+c^Tx \\\\ s.t. & \\quad Ax=b. \\end{aligned} \\] many methods solve equality constrained quadratic programming problem (Nocedal Wright 2006), direct elimination method, Schur matrix factorization method, generalized elimination method, iterative method .   full rank matrix \\(\\) positive definite matrix \\(Q\\), methods feasible. However, may encounter case \\(Q\\) positive semidefinite practice, solve problem using Lagrange dual QR factorization. Note solving PSD model using SQP algorithm, constraints compatible, negative infinity cases. Hence, property convex optimization, must solution problem. Since dealing small matrices, need use sparse matrix tricks.   apply KKT condition get equivalent statement \\[ \\begin{bmatrix} Q&^T\\\\&0 \\end{bmatrix} \\begin{bmatrix} x^*\\\\\\lambda^* \\end{bmatrix}= \\begin{bmatrix} -c\\\\b \\end{bmatrix}. \\] , solved system linear equations using QR factorization.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"inequality-constrained-quadratic-programming-problem","dir":"Articles","previous_headings":"Quadratic Programming Problem and Active Set Method","what":"Inequality constrained quadratic programming problem","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  inequality constrained quadratic programming problem, many methods solve , typical ones active set method (Goldfarb Idnani 1983) interior point method (Boyd Vandenberghe 2004), converge quickly. can also use alternating direction method multipliers (Boyd et al. 2011), Dykstra, slower convergence rate. Specific algorithms can derived special constraints sparse matrices, OSQP LowRankQP.   goal, need solve thousands small quadratic programming problems, require high convergence speed algorithm need consider case sparse matrices. use active set method, works well problem. also tried Dykstra algorithm, performed less well. time, specific problem, compared general linear constrained quadratic programming problem, certain convenience algorithm implementation.   Now, derive active set method.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"sequential-quadratic-programming-algorithm","dir":"Articles","previous_headings":"","what":"Sequential Quadratic Programming Algorithm","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  One effective methods nonlinearly constrained optimization generates steps solving quadratic subproblems. sequential quadratic programming (SQP) approach can used line search trust-region frameworks, appropriate small large problems.   First, consider problem equality constraints \\[ \\begin{split} min & \\quad f(x) \\\\ s.t. & \\quad c(x)=0, \\end{split} \\] \\(c(x)=\\big[c_1(x),\\ldots,c_m(x)\\big]^T\\).   Lagrangian function problem \\(\\mathcal{L}(x.\\lambda)=f(x)-\\lambda^Tc(x)\\). use \\((x)\\) denote Jacobian matrix constraints, \\[(x)^T=[\\nabla c_1(x),\\ldots,\\nabla c_m(x)].\\] first-order (KKT) conditions equlity-constrained problem can written system \\(n+m\\) equations \\(n+m\\) unknowns \\(x\\) \\(\\lambda\\): \\[F(x,\\lambda)=\\begin{bmatrix}\\nabla f(x)-(x)^T\\lambda\\\\c(x)\\end{bmatrix}=0.\\] solution \\((x^*,\\lambda^*)\\) equality-constrained problem \\((x^*)\\) full rank satisfies equations. can solve nonlinear equations using Newton’s method.   Jacobian \\(F(x,\\lambda)\\) \\[F'(x,\\lambda)=\\begin{bmatrix}\\nabla_{xx}^2\\mathcal{L}(x,\\lambda)&-(x)^T\\\\(x)&0\\end{bmatrix}.\\] Newton step iterate \\((x_k,\\lambda_k)\\) thus given \\[\\begin{bmatrix}x_{k+1}\\\\\\lambda_{k+1}\\end{bmatrix}=\\begin{bmatrix}x_k\\\\\\lambda_k\\end{bmatrix}+\\begin{bmatrix}p_k\\\\p_{\\lambda}\\end{bmatrix},\\] \\(p_k\\) \\(p_{\\lambda}\\) solve Newton-KKT system \\[\\begin{bmatrix}\\nabla_{xx}^2\\mathcal{L}_k&-A_k^T\\\\A_k&0\\end{bmatrix}\\begin{bmatrix}p_k\\\\p_{\\lambda}\\end{bmatrix}=\\begin{bmatrix}-\\nabla f_k+A_k^T\\lambda_k\\\\-c_k\\end{bmatrix}.\\] Newton iteration well defined KKT matrix nonsingular.   alternative way view iteration . Suppose iterate \\((x_k,\\lambda_k)\\) model problem using quadratic program \\[\\begin{split} \\mathop{min}\\limits_p & \\quad f_(x)_k+\\nabla f_k^Tp+\\frac{1}{2}p^T\\nabla_{xx}^2\\mathcal{L}_kp \\\\ s.t. & \\quad A_kp+c_k=0. \\end{split}\\] original problem true, problem unique solution \\((p_k,l_k)\\) satisfies \\[\\nabla_{xx}^2\\mathcal{L}_kp_k+\\nabla f_k-A_k^Tl_k=0,\\] \\[A_kp_k+c_k=0.\\] vectors \\(p_k\\) \\(l_k\\) can identified solution Newton equations well. fact, subtract \\(A_k^T\\lambda_k\\) sides first equation Newton equations , obtain \\[\\begin{bmatrix}\\nabla_{xx}^2\\mathcal{L}_k&-A_k^T\\\\A_k&0\\end{bmatrix}\\begin{bmatrix}p_k\\\\\\lambda_{k+1}\\end{bmatrix}=\\begin{bmatrix}-\\nabla \\lambda_k\\\\-c_k\\end{bmatrix}.\\] Hence, nonsingularity coefficient matrix, \\(\\lambda_{k+1}=l_k\\) \\(p_k\\) solves quadratic program Newton equations.   new iterate \\(x_{k+1},\\lambda_{k+1}\\) can therefore defined either solution quadratic program iterate generated Newton’s method applied optimality conditions problem. viewpoints useful. Newton point view facilitates analysis, whereas SQP framework enables us derive practical algorithms extend technique inequality-constrained case.   now state SQP method simplest form. First, choose initial pair \\((x_0,\\lambda_0)\\) set \\(k=0\\). , evaluate \\(f_k\\), \\(\\nabla f_k\\), \\(\\nabla_{xx}^2\\mathcal{L}_k\\), \\(A_k\\). Next, solve quadratic program obtain \\(p_k\\), \\(l_k\\). Finally, set \\(x_{k+1}=x_k+p_k\\) \\(\\lambda_{k+1}=\\lambda_k\\). Repeat process convergence test satisfied.   inequality-constrained case, can use active set method.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"convexity-of-the-optimization-problem","dir":"Articles","previous_headings":"Fit PSD Model by SQP Algorithm","what":"Convexity of the optimization problem","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  objective solve following optimization problem \\[\\begin{split} \\mathop{max}\\limits_{P,F} & \\quad \\mathcal{L}(G|P^{(t)},F^{(t)}) \\\\ s.t. & \\quad \\sum_{k=1}^Kp_{ik}=1,\\quad =1,\\ldots,\\\\ & \\quad 0\\leq p_{ik}\\leq 1,\\quad =1,\\ldots,,\\quad k=1,\\ldots,K\\\\ & \\quad 0\\leq f_{kj}\\leq 1,\\quad j=1,\\ldots,J,\\quad k=1,\\ldots,K. \\end{split}\\]   can easily translate optimization problem standard form. optimization problem convex P F fixed F P fixed. fact, definition convex optimization problem, need show objective function convex, inequality constraint function convex, equality constraint function affine. Note three conditions naturally lead fact feasible set convex. last two conditions clearly satisfied. just prove fact negative log-likelihood \\(-\\mathcal{L}(G|P,F)\\) convex P F fixed F P fixed.   exploit two properties convex functions. First, nonnegative weighted sum convex functions \\(f=\\omega_1f_1+\\cdots+\\omega_mf_m\\) convex. Second, convexity composite affine map preserved. Specifically, suppose \\(f:\\mathbb{R}^n\\rightarrow\\mathbb{R}\\), \\(\\\\mathbb{R}^{n\\times m}\\), \\(b\\\\mathbb{R}^n\\). Define \\(g:\\mathbb{R}^m\\rightarrow\\mathbb{R}\\) \\(g(x)=f(Ax+b)\\), wuth \\(\\textbf{dom}(g)=\\{x|Ax+b\\\\textbf{dom}(f)\\}\\). , \\(f\\) convex, \\(g\\).   Using first property, simply state \\(-log\\Big[\\sum_{k=1}^Kp_{ik}f_{kj}\\Big]\\) convex, \\(-log\\Big[\\sum_{k=1}^Kp_{ik}(1-f_{kj})\\Big]\\) convex can proved similarly. Using second property, concavity \\(log\\) function, obvious.   Convexity makes block iteration amenable convex optimization techniques.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"derivation-of-the-algorithm","dir":"Articles","previous_headings":"Fit PSD Model by SQP Algorithm","what":"Derivation of the algorithm","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  fix \\(P\\) optimize \\(F\\), fix \\(F\\) optimize \\(P\\), . use method step, , second-order Taylor expansion approximation \\[f(x)=f(x^{(t)})+\\nabla f(x^{(t)})(x-x^{(t)})+\\frac{1}{2}(x-x^{(t)})^T\\nabla^2f(x^{(t)})(x-x^{(t)})\\] used transform original problem constrained quadratic programming problem. Let\\(\\Delta x^{(t)}=x-x^{(t)}\\).   Update \\(P\\). calculate first second partial derivatives (Hessian matrix) \\(P\\) condition \\(F\\) fixed \\[\\frac{\\partial\\mathcal{L}}{\\partial p_{ik}}=\\sum_{j=1}^J\\bigg[\\frac{g_{ij}f_{kj}}{\\sum_{k=1}^Kp_{ik}f_{kj}}+\\frac{(2-g_{ij})(1-f_{kj})}{\\sum_{k=1}^Kp_{ik}(1-f_{kj})}\\bigg],\\] \\[\\frac{\\partial^2\\mathcal{L}}{\\partial p_{ik}\\partial p_{il}}=-\\sum_{j=1}^J\\bigg[\\frac{g_{ij}f_{kj}f_{lj}}{(\\sum_{k=1}^Kp_{ik}f_{kj})^2}+\\frac{(2-g_{ij})(1-f_{kj})(1-f_{lj})}{(\\sum_{k=1}^Kp_{ik}(1-f_{kj}))^2}\\bigg].\\] solve quadratic programming problem \\[\\begin{split} \\mathop{min}\\limits_{\\Delta P_i} & \\quad \\frac{1}{2}(\\Delta P_i)^T\\Big[-\\nabla^2_{P_i}\\mathcal{L}(G|P^{(t)},F^{(t)})\\Big]\\Delta P_i-\\Big[\\nabla_{P_i}\\mathcal{L}(G|P^{(t)},F^{(t)})\\Big]^T\\Delta P_i-\\mathcal{L}(G|P^{(t)},F^{(t)}) \\\\ s.t. & \\quad 1^T\\Delta P_i=0 \\\\ & \\quad 1-P_i^{(t)}\\geq\\Delta P_i\\geq-P_i^{(t)} \\end{split}\\] using active set method. Thus, \\(P_i^{(t+1)}=P_i^{(t)}+\\Delta P_i\\).   Update \\(F\\). calculate first second partial derivatives (Hessian matrix) \\(F\\) condition \\(P\\) fixed \\[\\frac{\\partial\\mathcal{L}}{\\partial f_{kj}}=\\sum_{=1}^\\bigg[\\frac{g_{ij}p_{ik}}{\\sum_{k=1}^Kp_{ik}f_{kj}}-\\frac{(2-g_{ij})p_{ik}}{\\sum_{k=1}^Kp_{ik}(1-f_{kj})}\\bigg],\\] \\[\\frac{\\partial^2\\mathcal{L}}{\\partial f_{kj}\\partial f_{lj}}=-\\sum_{=1}^\\bigg[\\frac{g_{ij}p_{ik}p_{il}}{(\\sum_{k=1}^Kp_{ik}f_{kj})^2}+\\frac{(2-g_{ij})p_{ik}p_{il}}{(\\sum_{k=1}^Kp_{ik}(1-f_{kj}))^2}\\bigg].\\] solve quadratic programming problem \\[\\begin{split} \\mathop{min}\\limits_{\\Delta F_j} & \\quad \\frac{1}{2}(\\Delta F_j)^T\\Big[-\\nabla^2_{F_j}\\mathcal{L}(G|P^{(t)},F^{(t)})\\Big]\\Delta F_j-\\Big[\\nabla_{F_j}\\mathcal{L}(G|P^{(t)},F^{(t)})\\Big]^T\\Delta F_j-\\mathcal{L}(G|P^{(t)},F^{(t)}) \\\\ s.t. & \\quad 1-F_j^{(t)}\\geq\\Delta F_j\\geq-F_j^{(t)} \\end{split}\\] using active set method. Thus, \\(F_j^{(t+1)}=F_j^{(t)}+\\Delta F_j\\).   conclusion, update \\(P\\) \\(F\\) block block alternately, log-likelihood incomplete data \\(\\mathcal{L}(G|P,F)\\) converges. SQP algorithm PSD model.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"acceleration","dir":"Articles","previous_headings":"","what":"Acceleration","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  can speed SQP algorithm three ways. First, write core parameter update part C++. Second, can choose different methods solve quadratic programming problems specifically solve large-scale systems small linear equations. Third, can use quasi Newtonian method accelerate algorithm, effect method remarkable.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/06_theory_sqp.html","id":"algorithm-implementation","dir":"Articles","previous_headings":"","what":"Algorithm Implementation","title":"Models and Methods II: Fit PSD Model by SQP Algorithm","text":"  Select suitable QR decomposition Eigen library (Guennebaud et al. 2022), speed accuracy compared following table.   present implementation SQP algorithm R package AwesomePackage. can fit PSD model using SQP algorithm using function psd_fit_sqp. time, can use plot_loss see changes log-likelihood plot_structure plot structure.   example.     See AwesomePackage details.","code":"library(AwesomePackage) G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) result <- psd_fit_sqp(G, 2, 1e-5, 50, 10) result ## $P ##             [,1]        [,2] ## [1,] 0.999999999 0.000000001 ## [2,] 0.000000001 0.999999999 ## [3,] 0.689179272 0.310820728 ##  ## $F ##             [,1]  [,2]        [,3]        [,4]        [,5] ## [1,] 0.276578102 1e-09 0.573747398 0.000000001 0.311700456 ## [2,] 0.000000001 1e+00 0.000000001 0.413493316 0.000000001 ##  ## $Loss ## [1] -0.7211319 -0.7074246 -0.7074246 ##  ## $Iterations ## [1] 30 L <- result$Loss plot_loss(list(L), \"sqp\", 10) P <- result$P plot_structure(P)"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  use variational inference algorithm (VI) fit PSD model (Raj, Stephens, Pritchard 2014).","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"psd-model","dir":"Articles","previous_headings":"","what":"PSD Model","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  Suppose \\(\\) diploid individuals genotyped \\(J\\) biallelic loci. Let \\((g_{ij}^1,g_{ij}^2)\\) represents genotype marker \\(j\\) person \\(\\), \\(g_{ij}^\\) represent observed number copies allele 1 seat \\(\\). Thus, \\((g_{ij}^1,g_{ij}^2)\\) equals \\((1,1)\\), \\((1,0)\\), \\((0,1)\\), \\((0,0)\\) accordingly, \\(\\) genotype 1/1, 1/2, 2/1, 2/2 marker \\(j\\). Let \\(g_{ij}=g_{ij}^1+g_{ij}^2\\). individuals drawn admixed population contributions \\(K\\) postulated ancestral populations. Population \\(k\\) contributes fraction \\(p_{ik}\\) individual \\(\\)’s genome. Note \\(\\sum_{k=1}^Kp_{ik}=1\\), \\(p_{ik}\\geq 0\\). Allele 1 SNP \\(j\\) frequency \\(f_{kj}\\) population \\(k\\). Note \\(0\\leq f_{kj}\\leq 1\\). Similar EM algorithm, consider \\((z_{ij}^1,z_{ij}^2)\\), \\(z_{ij}^\\) element set \\(\\{1,\\ldots,K\\}\\), denotes population genes individual \\(\\) marker \\(j\\) position \\(\\) really come. Let \\(z_{ijk}^=\\textbf{1}(z_{ij}^=k)\\), obviously, \\(z_{ijk}^\\\\{0,1\\}\\), \\(\\sum_{k=1}^Kz_{ijk}^=1\\).   Different EM SQP algorithms, variational inference optimize maximum likelihood \\(\\mathcal{L}(G|P,F)\\), posterior \\(P(Z,P,F|G)\\), also reflects difference frequency school Bayesian school. specific, previous assumptions, observed variable \\(G\\), unobserved variables include latent variable \\(Z\\) parameters \\(P\\), \\(F\\). take unobserved variables together variational objects, involved estimation. time, take model parameter \\(K\\), involved estimation, hyperparameter.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"variational-inference-algorithm","dir":"Articles","previous_headings":"","what":"Variational Inference Algorithm","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  goal Bayesian analysis estimate posterior. variational inference, use family densities latent variables \\(Q(z)\\), parameterized free approximate true posterior \\(P(z|x)\\) (Blei, Kucukelbir, McAuliffe 2017). variational inference, examine latent variables without considering model parameters. can transform optimization problem, namely minimization problem KL divergence \\[\\hat{Q}(z)=\\mathop{argmin}\\limits_{Q(z)}KL(Q(z)\\|P(z|x)).\\] addition, KL divergence generally directly solved. Note \\[log P(x)=ELBO(Q(z)) + KL(Q(z)\\|P(z|x)),\\] can transform problem maximization problem ELBO \\[\\hat{Q}(z)=\\mathop{argmax}\\limits_{Q(z)}ELBO(Q(z)).\\]   focus , latent variables mutually independent governed distinct factor variational density. generic member mean-field variational family \\(Q(z)=\\prod_{j=1}^{m}Q_j(z_j)\\). Emphasize \\(Q(z)\\) parameterized free 1.   Now derive coordinate ascent variational inference (CAVI). compute ELBO \\[ELBO(Q(z))=\\int_{z}Q(z)log P(x,z)dz-\\int_{z}Q(z)log Q(z)dz.\\] Note two terms ELBO reflect balance likelihood prior. Consider \\(Q_j\\) fix \\(Q_i\\), \\(\\neq j\\), \\[\\begin{split} &\\int_{z}Q(z)log P(x,z)dz \\\\ =& \\int_{z}\\prod_{=1}^mQ_i(z_i)logP(x,z)dz \\\\ =& \\int_{z_j}Q_j(z_j)\\Big[\\int_{z_{-j}}\\prod\\limits_{\\neq j}Q_i(z_i)logP(x,z)dz_{-j}\\Big]dz_j \\\\ =& \\int_{z_j}Q_j(z_j)\\mathbb{E}_{\\prod\\limits_{\\neq j}Q_j(z_j)}\\Big[log P(x,z)\\Big]dz_j \\\\ :=& \\int_{z_j}Q_j(z_j)log \\hat{P}(x,z_j)dz_j, \\end{split}\\] \\(z_{-j}\\) means traverse elements except \\(j\\). second term, \\[\\begin{split} & \\int_{z}Q(z)log Q(z)dz\\\\ =& \\int_{z}\\prod_{=1}^mQ_i(z_i)\\sum_{=1}^mlogQ_i(z_i)dz \\\\ =& \\sum_{=1}^m\\int_{z_i}Q_i(z_i)logQ_i(z_i)\\Big[\\int_{z_{-}}\\prod_{k\\neq }Q_k(z_k)dz_{-}\\Big]dz_i \\\\ =& \\sum_{=1}^m\\int_{z_i}Q_i(z_i)logQ_i(z_i)dz_i \\\\ =& \\int_{z_j}Q_j(z_j)logQ_j(z_j)dz_j+Const. \\end{split}\\] Thus, ELBO can denoted \\[ELBO(Q(z)) = \\int_{z_j}Q_j(z_j)log\\frac{\\hat{P}(x,z_j)}{Q_j(z_j)}dz_j+Const = -KL(Q_j(z_j)\\|\\hat{P}(x,z_j))+Const \\leq Const,\\] equality holds \\(\\hat{Q}_j(z_j)=\\hat{P}(x,z_j)\\), coordinate update formula CAVI. can use formula (equivalent ELBO taking partial derivative 0 respect \\(Q(z_j)\\)) obtain iterations variational parameters, derivation procedure guarantees ELBO eventually converge (local) minima.   conclusion, first select appropriate parameterized variational family, use coordinate ascent formula update variational parameters iteratively ELBO converges. VI algorithm.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"the-variational-family","dir":"Articles","previous_headings":"Fit PSD Model by VI Algorithm","what":"The variational family","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  choice variational family restricted tractability computing expectations respect variational distributions; , choose parametric distributions conjugate distributions likelihood function. Note likelihood function \\[\\begin{split} &P(G,Z,P,F|K)\\\\ =&P(G|Z,P,F,K)P(Z|P,F,K)P(P,F|K)\\\\ =&\\prod_{=1}^\\prod_{j=1}^J\\prod_{k=1}^K\\prod_{=1}^2Binomial\\Big(g_{ij}^\\Big|1,f_{kj}\\Big)^{z_{ijk}^}\\cdot\\prod_{=1}^\\prod_{j=1}^J\\prod_{=1}^2Multinomial\\Big(\\big(z_{ij1}^,\\ldots,z_{ijK}^\\big)\\Big|1,\\big(p_{i1},\\ldots,p_{iK}\\big)\\Big)\\cdot P(P,F|K)\\\\ =&\\prod_{=1}^\\prod_{j=1}^J\\prod_{=1}^2\\bigg[Multinomial\\Big(\\big(z_{ij1}^,\\ldots,z_{ijK}^\\big)\\Big|1,\\big(f_{1j}^{g_{ij}^}(1-f_{1j})^{1-{g_{ij}^}}p_{i1},\\ldots,f_{Kj}^{g_{ij}^}(1-f_{Kj})^{1-{g_{ij}^}}p_{iK}\\big)\\Big)\\bigg]\\cdot P(P,F|K). \\end{split}\\] \\(f_{kj}\\) parameter binomial distribution, naturally choose conjugate distribution, beta distribution, parameterized variational family \\(f_{kj}\\). \\(p_i=(p_{i1},\\ldots,p_{iK})\\) parameter multinomial distribution, naturally choose conjugate distribution, Dirichlet distribution, parameterized variational family \\(p_i\\). \\(z_{ij}^=(z_{ij1}^,\\ldots,z_{ijK}^)\\) obey multinomial distribution, naturally choose multinomial distribution parameterized variational family \\(z_{ij}^\\).   Using independence, choose variational family \\[Q(Z,P,F)=\\prod_{=1}^\\prod_{j=1}^J\\prod_{=1}^2Q(z_{ij}^)\\cdot\\prod_{=1}^IQ(p_i)\\cdot\\prod_{j=1}^J\\prod_{k=1}^KQ(f_{kj}),\\] factor can written \\[Q(z_{ij}^)\\sim Multinomial(\\tilde{z}_{ij}^),\\] \\[Q(p_i)\\sim Dirichlet(\\tilde{p}_i),\\] \\[Q(f_{kj})\\sim Beta(\\tilde{f}_{kj}^1,\\tilde{f}_{kj}^2).\\] \\(\\tilde{z}_{ij}^\\), \\(\\tilde{p}_i\\), \\(\\tilde{f}_{kj}^1\\), \\(\\tilde{f}_{kj}^2\\) parameters variational distributions (variational parameters).","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"elbo","dir":"Articles","previous_headings":"Fit PSD Model by VI Algorithm","what":"ELBO","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  repeat idea variational inference. KL divergence quantifies tightness lower bound log-marginal likelihood data. Specifically, variational distribution \\(Q(Z,P,F)\\), \\[logP(G)=ELBO(Q(Z,P,F)) + KL(Q(Z,P,F)\\|P(Z,P,F|G)),\\] omit model parameter \\(K\\) (involved estimation). Thus, minimizing KL divergence equivalent maximizing log-marginal likelihood lower bound (ELBO) data \\[\\begin{split} &\\hat{Q}(Z,P,F)\\\\ =&\\mathop{argmin}\\limits_{Q(Z,P,F)}KL(Q(Z,P,F)\\|P(Z,P,F|G))\\\\ =&\\mathop{argmin}\\limits_{Q(Z,P,F)}\\Big[logP(G)-ELBO(Q(Z,P,F))\\Big]\\\\ =&\\mathop{argmax}\\limits_{Q(Z,P,F)}ELBO(Q(Z,P,F)). \\end{split}\\]   Using Bayes’ formula, ELBO observed genotypes can written \\[\\begin{split} &ELBO(Q(Z,P,F))\\\\ =&\\ldots \\end{split}\\]   calculate variational parameterized ELBO \\[ \\begin{split} ELBO=&\\sum_{=1}^\\sum_{j=1}^J\\bigg\\{\\sum_{k=1}^K\\Big(\\mathbb{E}[z_{ijk}^1]+\\mathbb{E}[z_{ijk}^2]\\Big)\\Big(\\textbf{1}(g_{ij}=0)\\mathbb{E}[log(1-f_{kj})]+\\textbf{1}(g_{ij}=2)\\mathbb{E}[logf_{kj}]+\\mathbb{E}[logp_{ik}]\\Big)\\\\ &+\\textbf{1}(g_{ij}=1)\\sum_{k=1}^K\\Big(\\mathbb{E}[z_{ijk}^1]\\mathbb{E}[logf_{kj}]+\\mathbb{E}[z_{ijk}^2]\\mathbb{E}[log(1-f_{kj})]\\Big)-\\mathbb{E}[logz_{ij}^1]-\\mathbb{E}[logz_{ij}^2]\\bigg\\}\\\\ &+\\sum_{j=1}^J\\sum_{k=1}^Klog\\frac{B(\\tilde{f}_{kj}^1,\\tilde{f}_{kj}^2)}{B(\\beta^1,\\beta^2)}+(\\beta^1-\\tilde{f}_{kj}^1)\\mathbb{E}[logf_{kj}]+(\\beta^2-\\tilde{f}_{kj}^2)\\mathbb{E}[log(1-f_{kj})]\\\\ &+\\sum_{=1}^\\bigg\\{\\sum_{k=1}^K(\\alpha_k-\\tilde{p}_{ik})\\mathbb{E}[logp_{ik}]+log\\Gamma(\\alpha_k)-log\\Gamma(\\tilde{p}_{ik})\\bigg\\}+log\\Gamma(\\sum_{k=1}^K\\tilde{p}_{ik})-log\\Gamma(\\sum_{k=1}^K\\alpha_k), \\end{split} \\] \\(\\alpha_k\\), \\(\\beta^1\\) \\(\\beta^2\\) parameters prior distribution.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"priors","dir":"Articles","previous_headings":"Fit PSD Model by VI Algorithm","what":"Priors","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  choose simple priors \\(P(p_i)=Dirichlet(\\frac{1}{K}\\textbf{1}_K)\\), \\(P(f_{kj})=Beta(1,1)\\). : different priors","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"update-parameters","dir":"Articles","previous_headings":"Fit PSD Model by VI Algorithm","what":"Update parameters","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"take partial derivative ELBO obtain parameter update formula \\[\\tilde{z}_{ijk}^1\\propto exp\\Big\\{\\textbf{1}(g_{ij}=0)\\psi(\\tilde{f}_{kj}^2)+\\textbf{1}(g_{ij}=1)\\psi(\\tilde{f}_{kj}^1)+\\textbf{1}(g_{ij}=2)\\psi(\\tilde{f}_{kj}^1)-\\psi(\\tilde{f}_{kj}^1+\\tilde{f}_{kj}^2)+\\psi(\\tilde{p}_{ik})-\\psi(\\sum_{k=1}^K\\tilde{p}_{ik})\\Big\\},\\] \\[\\tilde{z}_{ijk}^2\\propto exp\\Big\\{\\textbf{1}(g_{ij}=0)\\psi(\\tilde{f}_{kj}^2)+\\textbf{1}(g_{ij}=1)\\psi(\\tilde{f}_{kj}^2)+\\textbf{1}(g_{ij}=2)\\psi(\\tilde{f}_{kj}^1)-\\psi(\\tilde{f}_{kj}^1+\\tilde{f}_{kj}^2)+\\psi(\\tilde{p}_{ik})-\\psi(\\sum_{k=1}^K\\tilde{p}_{ik})\\Big\\},\\] \\[\\tilde{p}_{ik}=\\alpha_k+\\sum_{j=1}^J(\\tilde{z}_{ijk}^1+\\tilde{z}_{ijk}^2),\\] \\[\\tilde{f}_{kj}^1=\\beta^1+\\sum_{=1}^\\Big[\\textbf{1}(g_{ij}=1)\\tilde{z}_{ijk}^1+\\textbf{1}(g_{ij}=2)(\\tilde{z}_{ijk}^1+\\tilde{z}_{ijk}^2)\\Big],\\] \\[\\tilde{f}_{kj}^2=\\beta^2+\\sum_{=1}^\\Big[\\textbf{1}(g_{ij}=1)\\tilde{z}_{ijk}^2+\\textbf{1}(g_{ij}=0)(\\tilde{z}_{ijk}^1+\\tilde{z}_{ijk}^2)\\Big].\\] convergence criterion change ELBO small enough. Using Dirichlet distribution beta distribution expectations, \\(\\mathbb{E}[p_{ik}]=\\frac{\\tilde{p}_{ik}}{\\sum_{k=1}^K\\tilde{p}_{ik}}\\), \\(\\mathbb{E}[f_{kj}]=\\frac{\\tilde{f}_{kj}^1}{\\sum_{k=1}^K\\tilde{f}_{kj}^1+\\tilde{f}_{kj}^2}\\). : Lagrange, properties special distribution functions, lemma computing mathematical expectations, LDA","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/07_theory_vi.html","id":"algorithm-implementation","dir":"Articles","previous_headings":"","what":"Algorithm Implementation","title":"Models and Methods III: Fit PSD Model by VI Algorithm","text":"  present implementation VI algorithm R package AwesomePackage. can fit PSD model using VI algorithm using function psd_fit_vi. time, can use plot_loss see changes log-likelihood plot_structure plot structure.   example.     See AwesomePackage details.","code":"library(AwesomePackage) G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) result <- psd_fit_vi(G, 2, 1e-5, 50) result ## $P ##            [,1]       [,2] ## [1,] 0.06953159 0.93046841 ## [2,] 0.93550917 0.06449083 ## [3,] 0.32370543 0.67629457 ##  ## $F ##           [,1]      [,2]      [,3]      [,4]      [,5] ## [1,] 0.2725076 0.7660242 0.2494581 0.4499380 0.2133494 ## [2,] 0.3234154 0.2617459 0.5287321 0.1809813 0.3786267 ##  ## $Loss ## [1] -1.789321 -1.666572 -1.656413 -1.655340 -1.654613 ##  ## $Iterations ## [1] 50 L <- result$Loss plot_loss(list(L), \"vi\", 10) P <- result$P plot_structure(P)"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/08_theory_svi.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Models and Methods IV: Fit PSD Model by SVI Algorithm","text":"  use stochastic variational inference algorithm (SVI) fit PSD model (Gopalan et al. 2016).","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/08_theory_svi.html","id":"psd-model","dir":"Articles","previous_headings":"","what":"PSD Model","title":"Models and Methods IV: Fit PSD Model by SVI Algorithm","text":"  Suppose \\(\\) diploid individuals genotyped \\(J\\) biallelic loci. Let \\((g_{ij}^1,g_{ij}^2)\\) represents genotype marker \\(j\\) person \\(\\), \\(g_{ij}^\\) represent observed number copies allele 1 seat \\(\\). Thus, \\((g_{ij}^1,g_{ij}^2)\\) equals \\((1,1)\\), \\((1,0)\\), \\((0,1)\\), \\((0,0)\\) accordingly, \\(\\) genotype 1/1, 1/2, 2/1, 2/2 marker \\(j\\). Let \\(g_{ij}=g_{ij}^1+g_{ij}^2\\). individuals drawn admixed population contributions \\(K\\) postulated ancestral populations. Population \\(k\\) contributes fraction \\(p_{ik}\\) individual \\(\\)’s genome. Note \\(\\sum_{k=1}^Kp_{ik}=1\\), \\(p_{ik}\\geq 0\\). Allele 1 SNP \\(j\\) frequency \\(f_{kj}\\) population \\(k\\). Note \\(0\\leq f_{kj}\\leq 1\\). Similar EM algorithm, consider \\((z_{ij}^1,z_{ij}^2)\\), \\(z_{ij}^\\) element set \\(\\{1,\\ldots,K\\}\\), denotes population genes individual \\(\\) marker \\(j\\) position \\(\\) really come. Let \\(z_{ijk}^=\\textbf{1}(z_{ij}^=k)\\), obviously, \\(z_{ijk}^\\\\{0,1\\}\\), \\(\\sum_{k=1}^Kz_{ijk}^=1\\).   Different EM SQP algorithms, variational inference optimize maximum likelihood \\(\\mathcal{L}(G|P,F)\\), posterior \\(P(Z,P,F|G)\\), also reflects difference frequency school Bayesian school. specific, previous assumptions, observed variable \\(G\\), unobserved variables include latent variable \\(Z\\) parameters \\(P\\), \\(F\\). take unobserved variables together variational objects, involved estimation. time, take model parameter \\(K\\), involved estimation, hyperparameter.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/08_theory_svi.html","id":"stochastic-variational-inference-algorithm","dir":"Articles","previous_headings":"","what":"Stochastic Variational Inference Algorithm","title":"Models and Methods IV: Fit PSD Model by SVI Algorithm","text":"  Modern applications probability models often require analyzing massive data. However, posterior inference algorithms easily scale. CAVI exception. reason coordinate ascent structure algorithm requires iterating entire data set iteration. data set size grows, iteration becomes computationally expensive (Blei, Kucukelbir, McAuliffe 2017).   alternative coordinate ascent gradient-based optimization, climbs ELBO computing following gradient iteration. perspective key scaling variational inference using stochastic variational inference (SVI) (Hoffman et al. 2013), method combines natural gradients (Amari 1998) stochastic optimization (Amari 1998). repeatedly () subsamples data point full data set; (b) uses current global parameters compute optimal local parameters subsampled data point; (c) adjusts current global parameters appropriate way. : proof convergence algorithm","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/08_theory_svi.html","id":"fit-psd-model-by-svi-algorithm","dir":"Articles","previous_headings":"","what":"Fit PSD Model by SVI Algorithm","title":"Models and Methods IV: Fit PSD Model by SVI Algorithm","text":"  model, choice variational family VI algorithm. goal update global variable \\(P\\) iteratively. iteration, first sample SNP location \\(j\\) observations \\(g_{ij}\\) location. , sampled data, update \\(F\\) fixed \\(P\\) way VI convergence. Next, update global variable \\[\\tilde{p}_{ik}^{(t+1)}=(1-\\rho_t)\\tilde{p}_{ik}^{(t)}+\\rho_t\\big[\\alpha_k+J(\\tilde{z}_{ijk}^1+\\tilde{z}_{ijk}^2)\\big],\\] step size \\(\\rho_t=(\\tau_0+t)^{-\\kappa}\\). set \\(\\tau_0\\) 1 \\(\\kappa\\) 0.5. take validation set participate training, compute log-likelihood function validation set change small enough.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/08_theory_svi.html","id":"algorithm-implementation","dir":"Articles","previous_headings":"","what":"Algorithm Implementation","title":"Models and Methods IV: Fit PSD Model by SVI Algorithm","text":": implementation details","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/09_theory_model.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Models and Methods V: Relationship between PSD Model and Other Models","text":"  illustrate close relationship PSD model, Poisson NMF model, multinomial topic model LDA model, can optimize algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/09_theory_model.html","id":"details","dir":"Articles","previous_headings":"","what":"Details","title":"Models and Methods V: Relationship between PSD Model and Other Models","text":"  PSD model closely related multinomial topic model. precisely, PSD model (log-likelihood) similar probabilistic latent semantic analysis (PLSA) model (Hofmann 2001), PSD model (Bayesian posterior) similar latent dirichlet allocation (LDA) model (Blei, Ng, Jordan 2003). similar representation model, derivation algorithm . Even using algorithm multinomial topic model fit diploid genotype data can get good results. practical, strictly mathematically equivalent. fact, multinomial topic model shown equivalent Poisson NMF model (Carbonetto et al. 2021) widely used analyze population structure single-cell genes RNA.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Applications I: Simulated Data Sets","text":"  evaluate performance different learning algorithms, generated two groups simulated genotype data sets. simulated data set , focus influence strength population structure choice parameter K performance different algorithms. simulated data set B, focus performance different algorithms mixing ratio gap different individuals small.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"generate-the-data-set","dir":"Articles","previous_headings":"Simulated Data Set A","what":"Generate the data set","title":"Applications I: Simulated Data Sets","text":"  generated simulated data set (Raj, Stephens, Pritchard 2014) three steps. First, generate population scale matrix \\(P\\) using Dirichlet distribution; second step, gene scale matrix \\(F\\) generated using beta distribution. third step generate genotype matrix \\(G\\) using binomial distribution. set number individuals \\(\\) 600, number SNPs \\(J\\) 2500, number populations \\(K\\) 3.   Step 1. population scales sample drawn symmetric Dirichlet distribution simulate small amounts gene flow three populations. use \\(Dirichlet(\\frac{1}{10}\\textbf{1}_3)\\), course, implementation code, can adjust parameters Dirichlet distribution.   Step 2. ancestral allele frequencies \\(\\bar{f_j}\\) SNP drawn natural data set simulate allele frequencies natural populations. use HGDP data set. First, \\(\\bar{f_j}\\) equal total number suballeles observed \\(j\\)th SNP divided twice number individuals. , assume samples drawn three-population demographic model. edge weights correspond parameter \\(F_k\\) (Wright 1949) 1 model quantifies genetic drift three current populations ancestral population. choose \\((F_1,F_2,F_3)=(0.1,0.05,0.01)\\) simulate strong structure \\((F_1,F_2,F_3)=0.5\\times(0.1,0.05,0.01)\\) simulate weak structure. Thus, allele frequency given locus population drawn beta distribution (Balding Nichols 1995) \\(f_{kj}\\sim Beta\\Big(\\frac{1-F_k}{F_k}\\bar{f_j},\\frac{1-F_k}{F_k}(1-\\bar{f_j})\\Big)\\).   Step 3. According PSD model, element \\(g_{ij}\\) matrix \\(G\\) follows binomial distribution probability \\((PF)_{ij}=\\sum_{=1}^Kp_{ik}f_{kj}\\) number trials 2.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"fit-the-data","dir":"Articles","previous_headings":"Simulated Data Set A","what":"Fit the data","title":"Applications I: Simulated Data Sets","text":"  use function psd_simulation package AwesomePackage directly.   use different algorithms different K fit strong weak structure data sets respectively.   store result result_simuA.RData.","code":"library(AwesomePackage) data_simuA_strong <- psd_simulation(600, 2500, 3, type.id = \"A\",                                      parm_F = c(0.1, 0.05, 0.01)) data_simuA_weak <- psd_simulation(600, 2500, 3, type.id = \"A\",                                    parm_F = 0.5 * c(0.1, 0.05, 0.01)) result_simuA_strong_em_K3 <- psd_fit_em(data_simuA_strong$G, 3, 1e-5, 2000) # [===============>-----------------------------------------------] 520/2000 (44s) result_simuA_strong_em_K5 <- psd_fit_em(data_simuA_strong$G, 5, 1e-5, 2000) # [=================>---------------------------------------------] 580/2000 ( 2m)  result_simuA_strong_sqp_K3 <- psd_fit_sqp(data_simuA_strong$G, 3, 1e-5, 200, 200) # [================================================================] 200/200 (17s) # [=========>-------------------------------------------------------] 30/200 (17s) result_simuA_strong_sqp_K5 <- psd_fit_sqp(data_simuA_strong$G, 5, 1e-5, 200, 200) # [================================================================] 200/200 (37s) # [===============>-------------------------------------------------] 50/200 ( 1m)  result_simuA_strong_vi_K3 <- psd_fit_vi(data_simuA_strong$G, 3, 1e-5, 2000) # [===================>-------------------------------------------] 650/2000 (39s) result_simuA_strong_vi_K5 <- psd_fit_vi(data_simuA_strong$G, 5, 1e-5, 2000) # [================================>-----------------------------] 1070/2000 ( 1m)  result_simuA_strong_svi_K3 <- psd_fit_svi(data_simuA_strong$G, 3,                                           1e-5, 5e+5, 1e+4, 3,                                           100, 2000,                                           5e-2, 1e-1,                                           1, 0.5) # [==============>--------------------------------------------] 130000/5e+05 (13m) result_simuA_strong_svi_K5 <- psd_fit_svi(data_simuA_strong$G, 5,                                           1e-5, 5e+5, 1e+4, 3,                                           100, 2000,                                           5e-2, 1e-1,                                           1, 0.5) # [=============>---------------------------------------------] 120000/5e+05 (12m) result_simuA_weak_em_K3 <- psd_fit_em(data_simuA_weak$G, 3, 1e-5, 2000) # [====================>------------------------------------------] 660/2000 ( 1m) result_simuA_weak_em_K5 <- psd_fit_em(data_simuA_weak$G, 5, 1e-5, 2000) # [==================>--------------------------------------------] 610/2000 ( 2m)  result_simuA_weak_sqp_K3 <- psd_fit_sqp(data_simuA_weak$G, 3, 1e-5, 200, 200) # [================================================================] 200/200 (18s) # [===============>-------------------------------------------------] 50/200 (28s) result_simuA_weak_sqp_K5 <- psd_fit_sqp(data_simuA_weak$G, 5, 1e-5, 200, 200) # [================================================================] 200/200 (39s) # [===============>-------------------------------------------------] 50/200 ( 1m)  result_simuA_weak_vi_K3 <- psd_fit_vi(data_simuA_weak$G, 3, 1e-5, 2000) # [=====================>-----------------------------------------] 710/2000 (46s) result_simuA_weak_vi_K5 <- psd_fit_vi(data_simuA_weak$G, 5, 1e-5, 2000) # [=======================================================>------] 1810/2000 ( 2m)  result_simuA_weak_svi_K3 <- psd_fit_svi(data_simuA_weak$G, 3,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [=======================>------------------------------------] 2e+05/5e+05 (19m) result_simuA_weak_svi_K5 <- psd_fit_svi(data_simuA_weak$G, 5,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [==================>----------------------------------------] 160000/5e+05 (19m)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"results","dir":"Articles","previous_headings":"Simulated Data Set A","what":"Results","title":"Applications I: Simulated Data Sets","text":"  import data directly.","code":"load(system.file(\"extdata\", \"result_simuA.RData\", package = \"AwesomePackage\", mustWork = TRUE)) plot_structure(data_simuA_strong$P, pops = c(1,2,3),                title = \"Data Set: simuA (strong) | Method: REAL | K: 3\") plot_structure(result_simuA_strong_em_K3$P, pops = c(3,1,2),                title = \"Data Set: simuA (strong) | Method: EM | K: 3\") plot_structure(result_simuA_strong_sqp_K3$P, pops = c(2,3,1),                title = \"Data Set: simuA (strong) | Method: SQP | K: 3\") plot_structure(result_simuA_strong_vi_K3$P, pops = c(1,3,2),                title = \"Data Set: simuA (strong) | Method: VI | K: 3\") plot_structure(result_simuA_strong_svi_K3$P, pops = c(2,1,3),                title = \"Data Set: simuA (strong) | Method: SVI | K: 3\") plot_structure(result_simuA_strong_em_K5$P, pops = c(2,1,4,5,3),                title = \"Data Set: simuA (strong) | Method: EM | K: 5\") plot_structure(result_simuA_strong_sqp_K5$P, pops = c(5,1,2,4,3),                title = \"Data Set: simuA (strong) | Method: SQP | K: 5\") plot_structure(result_simuA_strong_vi_K5$P, pops = c(4,2,3,1,5),                title = \"Data Set: simuA (strong) | Method: VI | K: 5\") plot_structure(result_simuA_strong_svi_K5$P, pops = c(4,5,1,2,3),                title = \"Data Set: simuA (strong) | Method: SVI | K: 5\") plot_structure(data_simuA_weak$P, pops = c(1,2,3),                title = \"Data Set: simuA (weak) | Method: REAL | K: 3\") plot_structure(result_simuA_weak_em_K3$P, pops = c(3,1,2),                title = \"Data Set: simuA (weak) | Method: EM | K: 3\") plot_structure(result_simuA_weak_sqp_K3$P, pops = c(1,3,2),                title = \"Data Set: simuA (weak) | Method: SQP | K: 3\") plot_structure(result_simuA_weak_vi_K3$P, pops = c(1,2,3),                title = \"Data Set: simuA (weak) | Method: VI | K: 3\") plot_structure(result_simuA_weak_svi_K3$P, pops = c(1,2,3),                title = \"Data Set: simuA (weak) | Method: SVI | K: 3\") plot_structure(result_simuA_weak_em_K5$P, pops = c(4,3,1,2,5),                title = \"Data Set: simuA (weak) | Method: EM | K: 5\") plot_structure(result_simuA_weak_sqp_K5$P, pops = c(1,3,4,2,5),                title = \"Data Set: simuA (weak) | Method: SQP | K: 5\") plot_structure(result_simuA_weak_vi_K5$P, pops = c(2,5,4,1,3),                title = \"Data Set: simuA (weak) | Method: VI | K: 5\") plot_structure(result_simuA_weak_svi_K5$P, pops = c(3,1,2,4,5),                title = \"Data Set: simuA (weak) | Method: SVI | K: 5\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"discussion","dir":"Articles","previous_headings":"Simulated Data Set A","what":"Discussion","title":"Applications I: Simulated Data Sets","text":"  main purpose simulated data set study influence strength population structure choice parameter K performance different algorithms.   EM SQP algorithms, tend reveal details, , sensitive parameter K structure strength. appropriate parameter K, may advantage, reveals finer structure. However, parameter K large, phenomenon overfitting easy occur. addition, SQP algorithm accurate EM algorithm.   VI algorithm, notice results VI almost consistent parameter K structure strength changes. means VI algorithm tends reveal main factors, thereby ignoring smaller contributions. strength weakness.   SVI algorithm ideal choice many cases, can highlight main parts like VI, react acutely structure obvious like EM SQP.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"generate-the-data-set-1","dir":"Articles","previous_headings":"Simulated Data Set B","what":"Generate the data set","title":"Applications I: Simulated Data Sets","text":"  also use three steps generate simulated data set B. second step, set \\(F_k\\) 0.1. third step data set . just consider first step. set Gaussian density ancestral population centered location normalizing individual proportions sum 1 (Gopalan et al. 2016). case, ancestral population placed location evenly spaced along line. Individuals also positioned evenly line, proportions \\(p_{ik}\\) function proximity population’s location. set number individuals \\(\\) 1000, number SNPs \\(J\\) 5000, number populations \\(K\\) 5.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"fit-the-data-1","dir":"Articles","previous_headings":"Simulated Data Set B","what":"Fit the data","title":"Applications I: Simulated Data Sets","text":"  use function psd_simulation package AwesomePackage directly.   use different algorithms different K fit data set.   store result result_simuB.RData.","code":"data_simuB <- psd_simulation(1000, 5000, 5, type.id = \"B\") result_simuB_em_K3 <- psd_fit_em(data_simuB$G, 3, 1e-5, 2000) # [=========>-----------------------------------------------------] 330/2000 ( 2m) result_simuB_em_K5 <- psd_fit_em(data_simuB$G, 5, 1e-5, 2000) # [==============>------------------------------------------------] 480/2000 ( 5m)  result_simuB_sqp_K3 <- psd_fit_sqp(data_simuB$G, 3, 1e-5, 200, 200) # [================================================================] 200/200 ( 1m) # [============>----------------------------------------------------] 40/200 ( 1m) result_simuB_sqp_K5 <- psd_fit_sqp(data_simuB$G, 5, 1e-5, 200, 200) # [================================================================] 200/200 ( 2m) # [===================>---------------------------------------------] 60/200 ( 5m)  result_simuB_vi_K3 <- psd_fit_vi(data_simuB$G, 3, 1e-5, 2000) # [============>--------------------------------------------------] 400/2000 ( 1m) result_simuB_vi_K5 <- psd_fit_vi(data_simuB$G, 5, 1e-5, 2000) # [=======================>---------------------------------------] 770/2000 ( 3m)  result_simuB_svi_K3 <- psd_fit_svi(data_simuB$G, 3,                                    1e-5, 5e+5, 1e+4, 3,                                    100, 2000,                                    5e-2, 1e-1,                                    1, 0.5) # [============>----------------------------------------------] 110000/5e+05 (13m) result_simuB_svi_K5 <- psd_fit_svi(data_simuB$G, 5,                                    1e-5, 5e+5, 1e+4, 3,                                    100, 2000,                                    5e-2, 1e-1,                                    1, 0.5) # [================>------------------------------------------] 140000/5e+05 (20m)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"results-1","dir":"Articles","previous_headings":"Simulated Data Set B","what":"Results","title":"Applications I: Simulated Data Sets","text":"  import data directly.","code":"load(system.file(\"extdata\", \"result_simuB.RData\", package = \"AwesomePackage\", mustWork = TRUE)) plot_structure(data_simuB$P, pops = c(5,4,3,2,1),                title = \"Data Set: simuB | Method: REAL | K: 5\") plot_structure(result_simuB_em_K3$P, pops = c(3,1,2),                title = \"Data Set: simuB | Method: EM | K: 3\") plot_structure(result_simuB_sqp_K3$P, pops = c(2,1,3),                title = \"Data Set: simuB | Method: SQP | K: 3\") plot_structure(result_simuB_vi_K3$P, pops = c(1,3,2),                title = \"Data Set: simuB | Method: VI | K: 3\") plot_structure(result_simuB_svi_K3$P, pops = c(1,2,3),                title = \"Data Set: simuB | Method: SVI | K: 3\") plot_structure(result_simuB_em_K5$P, pops = c(1,3,5,2,4),                title = \"Data Set: simuB | Method: EM | K: 5\") plot_structure(result_simuB_sqp_K5$P, pops = c(2,5,4,3,1),                title = \"Data Set: simuB | Method: SQP | K: 5\") plot_structure(result_simuB_vi_K5$P, pops = c(4,3,2,5,1),                title = \"Data Set: simuB | Method: VI | K: 5\") plot_structure(result_simuB_svi_K5$P, pops = c(4,2,5,3,1),                title = \"Data Set: simuB | Method: SVI | K: 5\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/10_application_simu.html","id":"discussion-1","dir":"Articles","previous_headings":"Simulated Data Set B","what":"Discussion","title":"Applications I: Simulated Data Sets","text":"  main purpose simulated data set B study performance different algorithms mixing ratio gap different individuals small. case, EM algorithm SQP algorithm can faithfully reflect structure dataset (former better), VI algorithm SVI algorithm overemphasize features (former worse).","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Applications II: TGP Data Set","text":"  1000 Genomes Project (TGP), launched January 2008, international research effort establish far detailed catalogue human genetic variation. Scientists planned sequence genomes least one thousand anonymous participants number different ethnic groups within following three years, using newly developed technologies faster less expensive. 2012, sequencing 1092 genomes announced Nature publication (Abecasis et al. 2012), marking completion first phase 1000 Genomes Project. 1000 Genomes Project completed three phases far. See information.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"data-sources-and-preprocessing","dir":"Articles","previous_headings":"","what":"Data Sources and Preprocessing","title":"Applications II: TGP Data Set","text":"  use TGP data first phase. download data PLINK format . rename data following form.   use R package genio read PLINK format document convert gene data genotype matrix, element represents observed number copies minor allele marker j person . rows matrix represent individuals columns matrix represent SNPs. Now preprocess data. first remove rows missing rate greater 0.5%, assign remaining missing values mode, 0. order ensure feasibility iterative algorithm, delete rows row value. store processed data data_TGP_full.rda.   order simplify data processing conform setting model, randomly selected 5000 SNPs complete data transposed matrix. stored data data_TGP.rda.   make easier group data, download table . make corresponding tables TGP.tsv three columns individuals populations TGP dataset. Superpop represents large populations, Asians, Africans, Europeans. Pop represents small populations, Chinese, British, Norwegian. Indiv represents individuals.   read table R store map_TGP.rda.   data_TGP.rda map_TGP.rda built-data AwesomePackage. can find information Reference AwesomePackage.","code":"TGP ├── TGP.bed ├── TGP.bim ├── TGP.fam library(genio) # Load data TGP. TGP <- read_plink('TGP/TGP.bed') data_TGP_full <- TGP$X # Filters rows with missing values. NA_TGP <- which(rowSums(is.na(data_TGP_full)) > 0) # Remove rows with more than 0.5% NA. data_TGP_full <- data_TGP_full[which(rowMeans(is.na(data_TGP_full)) < 0.005), ] # Assign the missing value to 0. data_TGP_full[is.na(data_TGP_full)] <- 0 # Delete rows with the same row value. same_TGP <- vector() for(i in 1:nrow(data_TGP_full)) {   if(length(unique(data_TGP_full[i, ])) == 1)   {     same_TGP <- c(same_TGP, i)   } } data_TGP_full <- data_TGP_full[-same_TGP, ] # Save data. save(data_TGP_full, file=\"data_TGP_full.rda\") # A random sample of 5000 SNPs. data_TGP <- t(data_TGP_full[sample(c(1:nrow(data_TGP_full)), 5000), ]) # Save data. save(data_TGP, file=\"data_TGP.rda\") # Reading a MAP File. map_TGP <- read.table(\"TGP.tsv\", header=T, sep=\"\\t\") # Save data. save(map_TGP, file=\"map_TGP.rda\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"fit-the-data","dir":"Articles","previous_headings":"","what":"Fit the Data","title":"Applications II: TGP Data Set","text":"  use following four algorithms fit sampled data different K, collect evaluation indicators fitting results.","code":"library(AwesomePackage)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"em-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"EM algorithm","title":"Applications II: TGP Data Set","text":"  store result result_TGP_em.RData.","code":"result_TGP_em_K2 <- psd_fit_em(data_TGP, 2, 1e-5, 2000) # [=========>-----------------------------------------------------] 320/2000 ( 1m) result_TGP_em_K3 <- psd_fit_em(data_TGP, 3, 1e-5, 2000) # [===========>---------------------------------------------------] 390/2000 ( 2m) result_TGP_em_K4 <- psd_fit_em(data_TGP, 4, 1e-5, 2000) # [==============================>--------------------------------] 980/2000 (10m) result_TGP_em_K5 <- psd_fit_em(data_TGP, 5, 1e-5, 2000) # [==================>--------------------------------------------] 590/2000 ( 8m) result_TGP_em_K6 <- psd_fit_em(data_TGP, 6, 1e-5, 2000) # [==================>--------------------------------------------] 610/2000 (11m) result_TGP_em_K7 <- psd_fit_em(data_TGP, 7, 1e-5, 2000) # [=======================>---------------------------------------] 760/2000 (17m) result_TGP_em_K8 <- psd_fit_em(data_TGP, 8, 1e-5, 2000) # [==============================>--------------------------------] 970/2000 (28m) result_TGP_em_K9 <- psd_fit_em(data_TGP, 9, 1e-5, 2000) # [=======================>---------------------------------------] 760/2000 (26m) result_TGP_em_K10 <- psd_fit_em(data_TGP, 10, 1e-5, 2000) # [=========================>-------------------------------------] 830/2000 (39m) result_TGP_em_K11 <- psd_fit_em(data_TGP, 11, 1e-5, 2000) # [=============================>---------------------------------] 960/2000 ( 1h) result_TGP_em_K12 <- psd_fit_em(data_TGP, 12, 1e-5, 2000) # [============================>----------------------------------] 920/2000 ( 1h) result_TGP_em_K13 <- psd_fit_em(data_TGP, 13, 1e-5, 2000) # [===========================>-----------------------------------] 890/2000 ( 1h) result_TGP_em_K14 <- psd_fit_em(data_TGP, 14, 1e-5, 2000) # [==============================>-------------------------------] 1010/2000 ( 1h) result_TGP_em_K15 <- psd_fit_em(data_TGP, 15, 1e-5, 2000) # [================================>-----------------------------] 1080/2000 ( 2h)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"sqp-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"SQP algorithm","title":"Applications II: TGP Data Set","text":"  store result result_TGP_sqp.RData.","code":"result_TGP_sqp_K2 <- psd_fit_sqp(data_TGP, 2, 1e-5, 200, 200) # [================================================================] 200/200 (44s) # [=========>-------------------------------------------------------] 30/200 (29s) result_TGP_sqp_K3 <- psd_fit_sqp(data_TGP, 3, 1e-5, 200, 200) # [================================================================] 200/200 ( 1m) # [=========>-------------------------------------------------------] 30/200 ( 1m) result_TGP_sqp_K4 <- psd_fit_sqp(data_TGP, 4, 1e-5, 200, 200) # [================================================================] 200/200 ( 2m) # [============>----------------------------------------------------] 40/200 ( 2m) result_TGP_sqp_K5 <- psd_fit_sqp(data_TGP, 5, 1e-5, 200, 200) # [================================================================] 200/200 ( 2m) # [============>----------------------------------------------------] 40/200 ( 4m) result_TGP_sqp_K6 <- psd_fit_sqp(data_TGP, 6, 1e-5, 200, 200) # [================================================================] 200/200 ( 3m) # [============>----------------------------------------------------] 40/200 ( 6m) result_TGP_sqp_K7 <- psd_fit_sqp(data_TGP, 7, 1e-5, 200, 500) # [================================================================] 500/500 (11m) # [===============>-------------------------------------------------] 50/200 (10m) result_TGP_sqp_K8 <- psd_fit_sqp(data_TGP, 8, 1e-5, 200, 500) # [================================================================] 500/500 (14m) # [============>----------------------------------------------------] 40/200 (10m) result_TGP_sqp_K9 <- psd_fit_sqp(data_TGP, 9, 1e-5, 200, 500) # [================================================================] 500/500 (17m) # [============>----------------------------------------------------] 40/200 (13m) result_TGP_sqp_K10 <- psd_fit_sqp(data_TGP, 10, 1e-5, 200, 500) # [================================================================] 500/500 (23m) # [===================>---------------------------------------------] 60/200 (26m) result_TGP_sqp_K11 <- psd_fit_sqp(data_TGP, 11, 1e-5, 200, 500) # [================================================================] 500/500 (26m) # [===================>---------------------------------------------] 60/200 (32m) result_TGP_sqp_K12 <- psd_fit_sqp(data_TGP, 12, 1e-5, 200, 800) # [================================================================] 800/800 (50m) # [===================>---------------------------------------------] 60/200 (40m) result_TGP_sqp_K13 <- psd_fit_sqp(data_TGP, 13, 1e-5, 200, 800) # [================================================================] 800/800 ( 1h) # [======================>------------------------------------------] 70/200 ( 1h) result_TGP_sqp_K14 <- psd_fit_sqp(data_TGP, 14, 1e-5, 200, 800) # [================================================================] 800/800 ( 1h) # [===============================>--------------------------------] 100/200 ( 2h) result_TGP_sqp_K15 <- psd_fit_sqp(data_TGP, 15, 1e-5, 200, 800) # [================================================================] 800/800 ( 1h) # [=========================>---------------------------------------] 80/200 ( 2h)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"vi-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"VI algorithm","title":"Applications II: TGP Data Set","text":"  store result result_TGP_vi.RData.","code":"result_TGP_vi_K2 <- psd_fit_vi(data_TGP, 2, 1e-5, 2000) # [==========>----------------------------------------------------] 350/2000 ( 1m) result_TGP_vi_K3 <- psd_fit_vi(data_TGP, 3, 1e-5, 2000) # [==============>------------------------------------------------] 480/2000 ( 2m) result_TGP_vi_K4 <- psd_fit_vi(data_TGP, 4, 1e-5, 2000) # [================================>-----------------------------] 1050/2000 ( 4m) result_TGP_vi_K5 <- psd_fit_vi(data_TGP, 5, 1e-5, 2000) # [==========================>------------------------------------] 870/2000 ( 4m) result_TGP_vi_K6 <- psd_fit_vi(data_TGP, 6, 1e-5, 2000) # [=================================>----------------------------] 1090/2000 ( 6m) result_TGP_vi_K7 <- psd_fit_vi(data_TGP, 7, 1e-5, 2000) # [===============================>------------------------------] 1030/2000 ( 7m) result_TGP_vi_K8 <- psd_fit_vi(data_TGP, 8, 1e-5, 2000) # [===================================>--------------------------] 1160/2000 ( 8m) result_TGP_vi_K9 <- psd_fit_vi(data_TGP, 9, 1e-5, 2000) # [======================================================>-------] 1760/2000 (13m) result_TGP_vi_K10 <- psd_fit_vi(data_TGP, 10, 1e-5, 2000) # [================================================>-------------] 1590/2000 (13m) result_TGP_vi_K11 <- psd_fit_vi(data_TGP, 11, 1e-5, 2000) # [=====================================>------------------------] 1240/2000 (11m) result_TGP_vi_K12 <- psd_fit_vi(data_TGP, 12, 1e-5, 2000) # [==========================================>-------------------] 1380/2000 (13m) result_TGP_vi_K13 <- psd_fit_vi(data_TGP, 13, 1e-5, 2000) # [====================================================>---------] 1720/2000 (17m) result_TGP_vi_K14 <- psd_fit_vi(data_TGP, 14, 1e-5, 2000) # [==============================>-------------------------------] 1000/2000 (10m) result_TGP_vi_K15 <- psd_fit_vi(data_TGP, 15, 1e-5, 2000) # [=========================================================>----] 1870/2000 (31m)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"svi-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"SVI algorithm","title":"Applications II: TGP Data Set","text":"  store result result_TGP_svi.RData.","code":"result_TGP_svi_K2_sample <- psd_fit_svi(data_TGP, 2,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [==========>-------------------------------------------------] 90000/5e+05 ( 8m) result_TGP_svi_K3_sample <- psd_fit_svi(data_TGP, 3,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [=================>-----------------------------------------] 150000/5e+05 (18m) result_TGP_svi_K4_sample <- psd_fit_svi(data_TGP, 4,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [===========>------------------------------------------------] 1e+05/5e+05 (14m) result_TGP_svi_K5_sample <- psd_fit_svi(data_TGP, 5,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [==============>--------------------------------------------] 130000/5e+05 (19m) result_TGP_svi_K6_sample <- psd_fit_svi(data_TGP, 6,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [=======================>------------------------------------] 2e+05/5e+05 (33m) result_TGP_svi_K7_sample <- psd_fit_svi(data_TGP, 7,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [=======================>------------------------------------] 2e+05/5e+05 (35m) result_TGP_svi_K8_sample <- psd_fit_svi(data_TGP, 8,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [==========================>--------------------------------] 230000/5e+05 (44m) result_TGP_svi_K9_sample <- psd_fit_svi(data_TGP, 9,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [============>----------------------------------------------] 110000/5e+05 (22m) result_TGP_svi_K10_sample <- psd_fit_svi(data_TGP, 10,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [===========================>-------------------------------] 240000/5e+05 ( 1h) result_TGP_svi_K11_sample <- psd_fit_svi(data_TGP, 11,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [=================>-----------------------------------------] 150000/5e+05 (34m) result_TGP_svi_K12_sample <- psd_fit_svi(data_TGP, 12,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [==================>----------------------------------------] 160000/5e+05 (37m) result_TGP_svi_K13_sample <- psd_fit_svi(data_TGP, 13,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [===========>------------------------------------------------] 1e+05/5e+05 (23m) result_TGP_svi_K14_sample <- psd_fit_svi(data_TGP, 14,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [=======================>------------------------------------] 2e+05/5e+05 ( 1h) result_TGP_svi_K15_sample <- psd_fit_svi(data_TGP, 15,                                         1e-5, 5e+5, 1e+4, 3,                                         100, 2000,                                         5e-2, 1e-1,                                         1, 0.5) # [================>------------------------------------------] 140000/5e+05 (39m)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"evaluation-indicators","dir":"Articles","previous_headings":"Fit the Data","what":"Evaluation indicators","title":"Applications II: TGP Data Set","text":"  store result result_TGP_evaluate.RData.","code":"loglikelihood_TGP_em <- vector() error_TGP_em <- vector() for (i in 2:15) {   result <- get(paste(\"result_TGP_em_K\", i, sep=\"\"))   loglikelihood_TGP_em <- c(loglikelihood_TGP_em,                              result$L[length(result$L)])   error_TGP_em <- c(error_TGP_em,                      psd_error(data_TGP, result)) } rm(result) rm(i) loglikelihood_TGP_sqp <- vector() error_TGP_sqp <- vector() for (i in 2:15) {   result <- get(paste(\"result_TGP_sqp_K\", i, sep=\"\"))   loglikelihood_TGP_sqp <- c(loglikelihood_TGP_sqp,                               result$L[length(result$L)])   error_TGP_sqp <- c(error_TGP_sqp,                       psd_error(data_TGP, result)) } rm(result) rm(i) ELBO_TGP_vi <- vector() loglikelihood_TGP_vi <- vector() error_TGP_vi <- vector() for (i in 2:15) {   result <- get(paste(\"result_TGP_vi_K\", i, sep=\"\"))   ELBO_TGP_vi <- c(ELBO_TGP_vi,                     result$L[length(result$L)])   loglikelihood_TGP_vi <- c(loglikelihood_TGP_vi,                              psd_loglikelihood(data_TGP, result))   error_TGP_vi <- c(error_TGP_vi,                      psd_error(data_TGP, result)) } rm(result) rm(i) ind_J <- sample(2, ncol(data_TGP), replace = TRUE, prob = c(1 - 5e-2, 5e-2)) ind_I <- sample(2, nrow(data_TGP), replace = TRUE, prob = c(1 - 1e-1, 1e-1)) data_TGP_val <- data_TGP[ind_I == 2, ind_J == 2] loglikelihood_TGP_svi <- vector() for (i in 2:15) {   P_val <- get(paste(\"result_TGP_svi_K\", i, \"_sample\", sep=\"\"))$P[ind_I == 2, ]   loglikelihood_TGP_svi <- c(loglikelihood_TGP_svi,                               psd_loglikelihood_svi(data_TGP_val, i, P_val)) } rm(ind_J) rm(ind_I) rm(data_TGP_val) rm(P_val) rm(i)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"choose-k","dir":"Articles","previous_headings":"","what":"Choose K","title":"Applications II: TGP Data Set","text":"  import data directly.   Criteria choosing K: obvious gap indicators, smaller K preferred.    notice log-likelihood curves EM SQP continuous upward trend, due fact prior distribution constraint, prone overfitting. log-likelihood curves EM SQP slow K equals 4.   log-likelihood curve VI flattens K equals 4, shows optimal K 12.    log-likelihood curve SVI relatively irregular three reasons. First, use different training validation sets fit different K. Although finally fixed validation set calculating log-likelihood validation set, based assumption data equivalent. Second, convergence criterion may relatively loose, resulting cases really converge optimal value. Third, sensitivity algorithm initial value leads large errors single measurement.   log-likelihood curve SVI shows optimal K 11, 8, 9, 10, 11 good choices K.    error curves EM, SQP VI almost identical log-likelihood curves EM, SQP VI. error function computed based entire training set. way make meaningful compute error function validation set (involved training) evaluate algorithm using either normal validation cross validation.    ELBO curve VI shows curve oscillating K equals 3.   conclusion, note K around 4, fit already well. optimal K reached around 11, structure diagram, populations appear redundant time.","code":"load(system.file(\"extdata\", \"result_TGP_evaluate.RData\", package = \"AwesomePackage\", mustWork = TRUE)) plot_index_vs_K(list(loglikelihood_TGP_em, loglikelihood_TGP_sqp, loglikelihood_TGP_vi),                  c(\"em\", \"sqp\", \"vi\"), index.id = \"loglik\") plot_index_vs_K(list(loglikelihood_TGP_svi),                  \"svi\", index.id = \"loglik\") plot_index_vs_K(list(error_TGP_em, error_TGP_sqp, error_TGP_vi),                  c(\"em\", \"sqp\", \"vi\"), index.id = \"error\") plot_index_vs_K(list(ELBO_TGP_vi),                  \"vi\", index.id = \"elbo\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"full-data","dir":"Articles","previous_headings":"","what":"Full Data","title":"Applications II: TGP Data Set","text":"  fit complete data relatively good K using SVI algorithm.   addition, iterated million times case best K (equals 4 11).   store result result_TGP_full.RData. import data directly.    best K (equals 4 11), draw subtle structures. can compare results article (Gopalan et al. 2016), structure diagram almost .","code":"result_TGP_svi_K7_full <- psd_fit_svi(t(data_TGP_full), 7,                                       1e-5, 1e+6, 1e+4, 5,                                       100, 2000,                                       5e-3, 1e-1,                                       1, 0.5) # [========>--------------------------------------------------] 160000/1e+06 (34m) result_TGP_svi_K8_full <- psd_fit_svi(t(data_TGP_full), 8,                                       1e-5, 1e+6, 1e+4, 5,                                       100, 2000,                                       5e-3, 1e-1,                                       1, 0.5) # [===========>------------------------------------------------] 2e+05/1e+06 (47m) result_TGP_svi_K9_full <- psd_fit_svi(t(data_TGP_full), 9,                                       1e-5, 1e+6, 1e+4, 5,                                       100, 2000,                                       5e-3, 1e-1,                                       1, 0.5) # [========>--------------------------------------------------] 160000/1e+06 (40m) result_TGP_svi_K10_full <- psd_fit_svi(t(data_TGP_full), 10,                                       1e-5, 1e+6, 1e+4, 5,                                       100, 2000,                                       5e-3, 1e-1,                                       1, 0.5) # [=====>------------------------------------------------------] 1e+05/1e+06 (27m) result_TGP_svi_K11_full <- psd_fit_svi(t(data_TGP_full), 11,                                       1e-5, 1e+6, 1e+4, 5,                                       100, 2000,                                       5e-3, 1e-1,                                       1, 0.5) # [====>-------------------------------------------------------] 80000/1e+06 (23m) result_TGP_svi_K4_full_million <- psd_fit_svi(t(data_TGP_full), 4,                                               1e-9, 1e+6, 1e+5, 10,                                               100, 2000,                                               5e-3, 1e-1,                                               1, 0.5) # [============================================================] 1e+06/1e+06 ( 2h) result_TGP_svi_K11_full_million <- psd_fit_svi(t(data_TGP_full), 11,                                               1e-9, 1e+6, 1e+5, 10,                                               100, 2000,                                               5e-3, 1e-1,                                               1, 0.5) # [============================================================] 1e+06/1e+06 ( 4h) load(system.file(\"extdata\", \"result_TGP_full.RData\", package = \"AwesomePackage\", mustWork = TRUE)) label <- rownames(data_TGP) lpop <- unlist(map_TGP[1]) spop <- unlist(map_TGP[2]) indiv <- unlist(map_TGP[3]) plot_structure(result_TGP_svi_K7_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP (full) | Method: SVI | K: 7\") plot_structure(result_TGP_svi_K8_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP (full) | Method: SVI | K: 8\") plot_structure(result_TGP_svi_K9_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP (full) | Method: SVI | K: 9\") plot_structure(result_TGP_svi_K10_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP (full) | Method: SVI | K: 10\") plot_structure(result_TGP_svi_K11_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP (full) | Method: SVI | K: 11\") plot_structure(result_TGP_svi_K4_full_million$P,                 label = label, map.indiv = indiv, map.pop = spop, gap = 2, font.size = 6,                 title = \"Data Set: TGP (full) | Method: SVI (1e+6 interations) | K: 4\") plot_structure(result_TGP_svi_K11_full_million$P,                 label = label, map.indiv = indiv, map.pop = spop, gap = 2, font.size = 6,                 title = \"Data Set: TGP (full) | Method: SVI (1e+6 interations) | K: 11\")"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"convergence-accuracy","dir":"Articles","previous_headings":"Algorithm Evaluation","what":"Convergence accuracy","title":"Applications II: TGP Data Set","text":"  suitable K, SVI algorithm SQP algorithm perform best terms convergence accuracy, followed VI algorithm finally EM algorithm. See Get started AwesomePackage details.   unknown K, due lack prior constraints, EM algorithm SQP algorithm prone overfitting population number redundant. can see clearly Appendix B. Therefore, better use VI algorithm SVI algorithm select appropriate K.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"convergence-efficiency","dir":"Articles","previous_headings":"Algorithm Evaluation","what":"Convergence efficiency","title":"Applications II: TGP Data Set","text":"  addition measuring accuracy convergence, still need consider efficiency convergence. two indicators measure convergence efficiency, convergence speed (number iterations required achieve convergence) convergence time (time required single iteration). can plot convergence time using code , can see convergence speed plots Appendix .    EM algorithm poor terms convergence time convergence speed, convergence time increases rapidly increase K.   Although SQP algorithm good performance terms convergence speed, convergence time unaccelerated SQP algorithm extremely slow, increases rapidly increase K.   VI algorithm similar convergence speed EM algorithm (poor performance), terms convergence time, VI algorithm excellent performance, especially increase K, required time increases slowly.   Due different principles, consider convergence time SVI algorithm. Although performance convergence time SVI algorithm poor small data sets, time SVI algorithm almost related length single sampling (number individuals), say, complete data sets, convergence time SVI almost unchanged. means SVI irreplaceable advantages large data sets. Meanwhile, similar VI algorithm, change convergence time SVI algorithm relatively insensitive K. way, compared algorithms, convergence time SVI algorithm irregular due randomness sampling.","code":"L <- list(c(1,2,10,8,11,17,28,26,39,60,60,60,60,120),           c(1,2,4,6,9,21,24,30,49,58,90,120,180,180),           c(1,2,4,4,6,7,8,13,13,11,13,17,10,31),           c(8,18,14,19,33,35,44,22,60,34,37,23,60,39)) plot_index_vs_K(L, c(\"em\", \"sqp\", \"vi\", \"svi\"), index.id = \"time\",                  title = \"Data Set: TGP\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"algorithm-selection-criteria","dir":"Articles","previous_headings":"Algorithm Evaluation","what":"Algorithm selection criteria","title":"Applications II: TGP Data Set","text":"  conclusion, consider algorithm accuracy algorithm efficiency.   small data sets, can get good results using VI directly. can first use VI algorithm reach vicinity optimal value, use SQP algorithm improve convergence accuracy. reason SQP algorithm directly used unaccelerated SQP algorithm inefficient SQP algorithm extremely easy converge local minima.   large data sets, use SVI algorithm without question.   course, K unknown, pick K first, way .","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"AppendixA","dir":"Articles","previous_headings":"","what":"Appendix A","title":"Applications II: TGP Data Set","text":"","code":"load(system.file(\"extdata\", \"result_TGP_em.RData\", package = \"AwesomePackage\", mustWork = TRUE)) load(system.file(\"extdata\", \"result_TGP_sqp.RData\", package = \"AwesomePackage\", mustWork = TRUE)) load(system.file(\"extdata\", \"result_TGP_vi.RData\", package = \"AwesomePackage\", mustWork = TRUE)) load(system.file(\"extdata\", \"result_TGP_svi.RData\", package = \"AwesomePackage\", mustWork = TRUE)) plot_loss(list(result_TGP_em_K2$Loss[-1], result_TGP_sqp_K2$Loss[-1],                 result_TGP_vi_K2$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 2\") plot_loss(list(result_TGP_svi_K2_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 2\") plot_loss(list(result_TGP_em_K3$Loss[-1], result_TGP_sqp_K3$Loss[-1],                 result_TGP_vi_K3$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 3\") plot_loss(list(result_TGP_svi_K3_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 3\") plot_loss(list(result_TGP_em_K4$Loss[-1], result_TGP_sqp_K4$Loss[-1],                 result_TGP_vi_K4$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 4\") plot_loss(list(result_TGP_svi_K4_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 4\") plot_loss(list(result_TGP_em_K5$Loss[-1], result_TGP_sqp_K5$Loss[-1],                 result_TGP_vi_K5$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 5\") plot_loss(list(result_TGP_svi_K5_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 5\") plot_loss(list(result_TGP_em_K6$Loss[-1], result_TGP_sqp_K6$Loss[-1],                 result_TGP_vi_K6$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 6\") plot_loss(list(result_TGP_svi_K6_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 6\") plot_loss(list(result_TGP_em_K7$Loss[-1], result_TGP_sqp_K7$Loss[-1],                 result_TGP_vi_K7$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 7\") plot_loss(list(result_TGP_svi_K7_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 7\") plot_loss(list(result_TGP_em_K8$Loss[-1], result_TGP_sqp_K8$Loss[-1],                 result_TGP_vi_K8$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 8\") plot_loss(list(result_TGP_svi_K8_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 8\") plot_loss(list(result_TGP_em_K9$Loss[-1], result_TGP_sqp_K9$Loss[-1],                 result_TGP_vi_K9$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 9\") plot_loss(list(result_TGP_svi_K9_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 9\") plot_loss(list(result_TGP_em_K10$Loss[-1], result_TGP_sqp_K10$Loss[-1],                 result_TGP_vi_K10$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 10\") plot_loss(list(result_TGP_svi_K10_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 10\") plot_loss(list(result_TGP_em_K11$Loss[-1], result_TGP_sqp_K11$Loss[-1],                 result_TGP_vi_K11$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 11\") plot_loss(list(result_TGP_svi_K11_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 11\") plot_loss(list(result_TGP_em_K12$Loss[-1], result_TGP_sqp_K12$Loss[-1],                 result_TGP_vi_K12$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 12\") plot_loss(list(result_TGP_svi_K12_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 12\") plot_loss(list(result_TGP_em_K13$Loss[-1], result_TGP_sqp_K13$Loss[-1],                 result_TGP_vi_K13$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 13\") plot_loss(list(result_TGP_svi_K13_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 13\") plot_loss(list(result_TGP_em_K14$Loss[-1], result_TGP_sqp_K14$Loss[-1],                 result_TGP_vi_K14$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 14\") plot_loss(list(result_TGP_svi_K14_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 14\") plot_loss(list(result_TGP_em_K15$Loss[-1], result_TGP_sqp_K15$Loss[-1],                 result_TGP_vi_K15$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: TGP | K: 15\") plot_loss(list(result_TGP_svi_K15_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: TGP | K: 15\")"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"em-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"EM algorithm","title":"Applications II: TGP Data Set","text":"","code":"plot_structure(result_TGP_em_K2$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 2\") plot_structure(result_TGP_em_K3$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 3\") plot_structure(result_TGP_em_K4$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 4\") plot_structure(result_TGP_em_K5$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 5\") plot_structure(result_TGP_em_K6$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 6\") plot_structure(result_TGP_em_K7$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 7\") plot_structure(result_TGP_em_K8$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 8\") plot_structure(result_TGP_em_K9$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 9\") plot_structure(result_TGP_em_K10$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 10\") plot_structure(result_TGP_em_K11$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 11\") plot_structure(result_TGP_em_K12$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 12\") plot_structure(result_TGP_em_K13$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 13\") plot_structure(result_TGP_em_K14$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 14\") plot_structure(result_TGP_em_K15$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: EM | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"sqp-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"SQP algorithm","title":"Applications II: TGP Data Set","text":"","code":"plot_structure(result_TGP_sqp_K2$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 2\") plot_structure(result_TGP_sqp_K3$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 3\") plot_structure(result_TGP_sqp_K4$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 4\") plot_structure(result_TGP_sqp_K5$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 5\") plot_structure(result_TGP_sqp_K6$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 6\") plot_structure(result_TGP_sqp_K7$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 7\") plot_structure(result_TGP_sqp_K8$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 8\") plot_structure(result_TGP_sqp_K9$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 9\") plot_structure(result_TGP_sqp_K10$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 10\") plot_structure(result_TGP_sqp_K11$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 11\") plot_structure(result_TGP_sqp_K12$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 12\") plot_structure(result_TGP_sqp_K13$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 13\") plot_structure(result_TGP_sqp_K14$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 14\") plot_structure(result_TGP_sqp_K15$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SQP | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"vi-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"VI algorithm","title":"Applications II: TGP Data Set","text":"","code":"plot_structure(result_TGP_vi_K2$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 2\") plot_structure(result_TGP_vi_K3$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 3\") plot_structure(result_TGP_vi_K4$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 4\") plot_structure(result_TGP_vi_K5$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 5\") plot_structure(result_TGP_vi_K6$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 6\") plot_structure(result_TGP_vi_K7$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 7\") plot_structure(result_TGP_vi_K8$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 8\") plot_structure(result_TGP_vi_K9$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 9\") plot_structure(result_TGP_vi_K10$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 10\") plot_structure(result_TGP_vi_K11$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 11\") plot_structure(result_TGP_vi_K12$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 12\") plot_structure(result_TGP_vi_K13$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 13\") plot_structure(result_TGP_vi_K14$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 14\") plot_structure(result_TGP_vi_K15$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: VI | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/11_application_tgp.html","id":"svi-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"SVI algorithm","title":"Applications II: TGP Data Set","text":"","code":"plot_structure(result_TGP_svi_K2_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 2\") plot_structure(result_TGP_svi_K3_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 3\") plot_structure(result_TGP_svi_K4_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 4\") plot_structure(result_TGP_svi_K5_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 5\") plot_structure(result_TGP_svi_K6_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 6\") plot_structure(result_TGP_svi_K7_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 7\") plot_structure(result_TGP_svi_K8_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 8\") plot_structure(result_TGP_svi_K9_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 9\") plot_structure(result_TGP_svi_K10_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 10\") plot_structure(result_TGP_svi_K11_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 11\") plot_structure(result_TGP_svi_K12_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 12\") plot_structure(result_TGP_svi_K13_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 13\") plot_structure(result_TGP_svi_K14_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 14\") plot_structure(result_TGP_svi_K15_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: TGP | Method: SVI | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Applications III: HGDP Data Set","text":"  group scientists Stanford University collaborated large study understand genetic diversity human populations. analyzed genomic DNA 1,043 individuals around world, determining genotypes 650,000 SNP loci, Illumina BeadStation technology. Genomic DNA samples fully-consenting individuals collected Human Genome Diversity Project (HGDP), collaboration Centre Etude Polymorphism Humain (CEPH) Paris. collection tested referred “HGDP-CEPH Human Genome Diversity Cell Line Panel” (Cann et al. 2002). represent 51 different populations Africa, Europe, Middle East, South Central Asia, East Asia, Oceania Americas. HGDP includes 51 populations around world (Li et al. 2008). description populations studied can found 2005 review paper Cavalli-Sforza (Cavalli-Sforza 2005). See information.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"data-sources-and-preprocessing","dir":"Articles","previous_headings":"","what":"Data Sources and Preprocessing","title":"Applications III: HGDP Data Set","text":"  use Harvard HGDP-CEPH data (Lu et al. 2011). download data PLINK format . rename all_snp.map all_snp.ped HGDP.map HGDP.ped. , use PLINK code plink --file HGDP --make-bed --HGDP construct binary file. end following file.   use R package genio read PLINK format document convert gene data genotype matrix, element represents observed number copies minor allele marker j person . rows matrix represent individuals columns matrix represent SNPs. Now preprocess data. first remove rows missing rate greater 0.5%, assign remaining missing values mode, 0. order ensure feasibility iterative algorithm, delete rows row value. store processed data data_HGDP_full.rda.   order simplify data processing conform setting model, randomly selected 5000 SNPs complete data transposed matrix. stored data data_HGDP.rda.   make easier group data, make corresponding tables HGDP.txt three columns individuals populations HGDP dataset basis document sample_all_snp.txt 2008 paper (Li et al. 2008). Superpop represents large populations, Asians, Africans, Europeans. Pop represents small populations, Chinese, British, Norwegian. Indiv represents individuals.   read table R store map_HGDP.rda.   data_HGDP.rda map_HGDP.rda built-data AwesomePackage. can find information Reference AwesomePackage.","code":"HGDP ├── HGDP.bed ├── HGDP.bim ├── HGDP.fam ├── HGDP.map ├── HGDP.ped library(genio) # Load data HGDP. HGDP <- read_plink('HGDP/HGDP.bed') data_HGDP_full <- HGDP$X # Filters rows with missing values. NA_HGDP <- which(rowSums(is.na(data_HGDP_full)) > 0) # Remove rows with more than 0.5% NA. data_HGDP_full <- data_HGDP_full[which(rowMeans(is.na(data_HGDP_full)) < 0.005), ] # Assign the missing value to 0. data_HGDP_full[is.na(data_HGDP_full)] <- 0 # Delete rows with the same row value. same_HGDP <- vector() for(i in 1:nrow(data_HGDP_full)) {   if(length(unique(data_HGDP_full[i, ])) == 1)   {     same_HGDP <- c(same_HGDP, i)   } } data_HGDP_full <- data_HGDP_full[-same_HGDP, ] # Save data. save(data_HGDP_full, file=\"data_HGDP_full.rda\") # A random sample of 5000 SNPs. data_HGDP <- t(data_HGDP_full[sample(c(1:nrow(data_HGDP_full)), 5000), ]) # Save data. save(data_HGDP, file=\"data_HGDP.rda\") # Reading a MAP File. map_HGDP <- read.table(\"HGDP.txt\", header=T, sep=\"\\t\") # Save data. save(map_HGDP, file=\"map_HGDP.rda\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"fit-the-data","dir":"Articles","previous_headings":"","what":"Fit the Data","title":"Applications III: HGDP Data Set","text":"  use following four algorithms fit sampled data different K, collect evaluation indicators fitting results.","code":"library(AwesomePackage)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"em-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"EM algorithm","title":"Applications III: HGDP Data Set","text":"  store result result_HGDP_em.RData.","code":"result_HGDP_em_K2 <- psd_fit_em(data_HGDP, 2, 1e-5, 2000) # [============>--------------------------------------------------] 400/2000 ( 1m) result_HGDP_em_K3 <- psd_fit_em(data_HGDP, 3, 1e-5, 2000) # [===============>-----------------------------------------------] 500/2000 ( 3m) result_HGDP_em_K4 <- psd_fit_em(data_HGDP, 4, 1e-5, 2000) # [==============>------------------------------------------------] 480/2000 ( 4m) result_HGDP_em_K5 <- psd_fit_em(data_HGDP, 5, 1e-5, 2000) # [=======================>---------------------------------------] 750/2000 ( 9m) result_HGDP_em_K6 <- psd_fit_em(data_HGDP, 6, 1e-5, 2000) # [=========================>-------------------------------------] 830/2000 (13m) result_HGDP_em_K7 <- psd_fit_em(data_HGDP, 7, 1e-5, 2000) # [=======================================>----------------------] 1300/2000 (27m) result_HGDP_em_K8 <- psd_fit_em(data_HGDP, 8, 1e-5, 2000) # [===================>-------------------------------------------] 620/2000 (15m) result_HGDP_em_K9 <- psd_fit_em(data_HGDP, 9, 1e-5, 2000) # [========================>--------------------------------------] 780/2000 (25m) result_HGDP_em_K10 <- psd_fit_em(data_HGDP, 10, 1e-5, 2000) # [=========================>-------------------------------------] 830/2000 (34m) result_HGDP_em_K11 <- psd_fit_em(data_HGDP, 11, 1e-5, 2000) # [================================>-----------------------------] 1070/2000 ( 1h) result_HGDP_em_K12 <- psd_fit_em(data_HGDP, 12, 1e-5, 2000) # [========================>--------------------------------------] 800/2000 (44m) result_HGDP_em_K13 <- psd_fit_em(data_HGDP, 13, 1e-5, 2000) # [===========================>-----------------------------------] 900/2000 ( 1h) result_HGDP_em_K14 <- psd_fit_em(data_HGDP, 14, 1e-5, 2000) # [===============================>------------------------------] 1020/2000 ( 1h) result_HGDP_em_K15 <- psd_fit_em(data_HGDP, 15, 1e-5, 2000) # [================================>-----------------------------] 1050/2000 ( 1h)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"sqp-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"SQP algorithm","title":"Applications III: HGDP Data Set","text":"  store result result_HGDP_sqp.RData.","code":"result_HGDP_sqp_K2 <- psd_fit_sqp(data_HGDP, 2, 1e-5, 200, 200) # [================================================================] 200/200 (40s) # [=========>-------------------------------------------------------] 30/200 (28s) result_HGDP_sqp_K3 <- psd_fit_sqp(data_HGDP, 3, 1e-5, 200, 200) # [================================================================] 200/200 ( 1m) # [=========>-------------------------------------------------------] 30/200 ( 1m) result_HGDP_sqp_K4 <- psd_fit_sqp(data_HGDP, 4, 1e-5, 200, 200) # [================================================================] 200/200 ( 2m) # [============>----------------------------------------------------] 40/200 ( 2m) result_HGDP_sqp_K5 <- psd_fit_sqp(data_HGDP, 5, 1e-5, 200, 200) # [================================================================] 200/200 ( 2m) # [===============>-------------------------------------------------] 50/200 ( 5m) result_HGDP_sqp_K6 <- psd_fit_sqp(data_HGDP, 6, 1e-5, 200, 200) # [================================================================] 200/200 ( 3m) # [============>----------------------------------------------------] 40/200 ( 5m) result_HGDP_sqp_K7 <- psd_fit_sqp(data_HGDP, 7, 1e-5, 200, 500) # [================================================================] 500/500 (10m) # [=========>-------------------------------------------------------] 30/200 ( 5m) result_HGDP_sqp_K8 <- psd_fit_sqp(data_HGDP, 8, 1e-5, 200, 500) # [================================================================] 500/500 (13m) # [===============>-------------------------------------------------] 50/200 (12m) result_HGDP_sqp_K9 <- psd_fit_sqp(data_HGDP, 9, 1e-5, 200, 500) # [================================================================] 500/500 (15m) # [===============================================>----------------] 150/200 (44m) result_HGDP_sqp_K10 <- psd_fit_sqp(data_HGDP, 10, 1e-5, 200, 500) # [================================================================] 500/500 (20m) # [============>----------------------------------------------------] 40/200 (15m) result_HGDP_sqp_K11 <- psd_fit_sqp(data_HGDP, 11, 1e-5, 200, 500) # [================================================================] 500/500 (24m) # [==================================>-----------------------------] 110/200 ( 1h) result_HGDP_sqp_K12 <- psd_fit_sqp(data_HGDP, 12, 1e-5, 200, 800) # [================================================================] 800/800 (44m) # [===================>---------------------------------------------] 60/200 (36m) result_HGDP_sqp_K13 <- psd_fit_sqp(data_HGDP, 13, 1e-5, 200, 800) # [================================================================] 800/800 ( 1h) # [=========================>---------------------------------------] 80/200 ( 1h) result_HGDP_sqp_K14 <- psd_fit_sqp(data_HGDP, 14, 1e-5, 200, 800) # [================================================================] 800/800 ( 1h) # [===============>-------------------------------------------------] 50/200 (43m) result_HGDP_sqp_K15 <- psd_fit_sqp(data_HGDP, 15, 1e-5, 200, 800) # [================================================================] 800/800 ( 1h) # [===============>-------------------------------------------------] 50/200 ( 1h)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"vi-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"VI algorithm","title":"Applications III: HGDP Data Set","text":"  store result result_HGDP_vi.RData.","code":"result_HGDP_vi_K2 <- psd_fit_vi(data_HGDP, 2, 1e-5, 2000) # [================================>-----------------------------] 1070/2000 ( 3m) result_HGDP_vi_K3 <- psd_fit_vi(data_HGDP, 3, 1e-5, 2000) # [============>--------------------------------------------------] 410/2000 ( 1m) result_HGDP_vi_K4 <- psd_fit_vi(data_HGDP, 4, 1e-5, 2000) # [========================>--------------------------------------] 800/2000 ( 3m) result_HGDP_vi_K5 <- psd_fit_vi(data_HGDP, 5, 1e-5, 2000) # [================================>-----------------------------] 1060/2000 ( 5m) result_HGDP_vi_K6 <- psd_fit_vi(data_HGDP, 6, 1e-5, 2000) # [==============================>--------------------------------] 990/2000 ( 5m) result_HGDP_vi_K7 <- psd_fit_vi(data_HGDP, 7, 1e-5, 2000) # [============================>----------------------------------] 910/2000 ( 5m) result_HGDP_vi_K8 <- psd_fit_vi(data_HGDP, 8, 1e-5, 2000) # [=============================>---------------------------------] 960/2000 ( 6m) result_HGDP_vi_K9 <- psd_fit_vi(data_HGDP, 9, 1e-5, 2000) # [=================================>----------------------------] 1090/2000 ( 7m) result_HGDP_vi_K10 <- psd_fit_vi(data_HGDP, 10, 1e-5, 2000) # [=================================>----------------------------] 1090/2000 ( 8m) result_HGDP_vi_K11 <- psd_fit_vi(data_HGDP, 11, 1e-5, 2000) # [====================================>-------------------------] 1200/2000 ( 9m) result_HGDP_vi_K12 <- psd_fit_vi(data_HGDP, 12, 1e-5, 2000) # [============================>----------------------------------] 930/2000 ( 8m) result_HGDP_vi_K13 <- psd_fit_vi(data_HGDP, 13, 1e-5, 2000) # [==============================>-------------------------------] 1010/2000 ( 9m) result_HGDP_vi_K14 <- psd_fit_vi(data_HGDP, 14, 1e-5, 2000) # [==============================================>---------------] 1520/2000 (14m) result_HGDP_vi_K15 <- psd_fit_vi(data_HGDP, 15, 1e-5, 2000) # [====================================>-------------------------] 1190/2000 (12m)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"svi-algorithm","dir":"Articles","previous_headings":"Fit the Data","what":"SVI algorithm","title":"Applications III: HGDP Data Set","text":"  store result result_HGDP_svi.RData.","code":"result_HGDP_svi_K2_sample <- psd_fit_svi(data_HGDP, 2,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [=========>--------------------------------------------------] 80000/5e+05 ( 8m) result_HGDP_svi_K3_sample <- psd_fit_svi(data_HGDP, 3,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [=================>-----------------------------------------] 150000/5e+05 (16m) result_HGDP_svi_K4_sample <- psd_fit_svi(data_HGDP, 4,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [==========================>--------------------------------] 230000/5e+05 (28m) result_HGDP_svi_K5_sample <- psd_fit_svi(data_HGDP, 5,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [==================>----------------------------------------] 160000/5e+05 (22m) result_HGDP_svi_K6_sample <- psd_fit_svi(data_HGDP, 6,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [===============================>---------------------------] 270000/5e+05 (40m) result_HGDP_svi_K7_sample <- psd_fit_svi(data_HGDP, 7,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [=============>---------------------------------------------] 120000/5e+05 (20m) result_HGDP_svi_K8_sample <- psd_fit_svi(data_HGDP, 8,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [===========>------------------------------------------------] 1e+05/5e+05 (17m) result_HGDP_svi_K9_sample <- psd_fit_svi(data_HGDP, 9,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [===================>---------------------------------------] 170000/5e+05 (31m) result_HGDP_svi_K10_sample <- psd_fit_svi(data_HGDP, 10,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [================================>--------------------------] 280000/5e+05 ( 1h) result_HGDP_svi_K11_sample <- psd_fit_svi(data_HGDP, 11,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [==============>--------------------------------------------] 130000/5e+05 (26m) result_HGDP_svi_K12_sample <- psd_fit_svi(data_HGDP, 12,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [=====================>-------------------------------------] 190000/5e+05 (41m) result_HGDP_svi_K13_sample <- psd_fit_svi(data_HGDP, 13,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [========================================>------------------] 350000/5e+05 ( 1h) result_HGDP_svi_K14_sample <- psd_fit_svi(data_HGDP, 14,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [==========>-------------------------------------------------] 90000/5e+05 (21m) result_HGDP_svi_K15_sample <- psd_fit_svi(data_HGDP, 15,                                          1e-5, 5e+5, 1e+4, 3,                                          100, 2000,                                          5e-2, 1e-1,                                          1, 0.5) # [===========================================>---------------] 370000/5e+05 ( 2h)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"evaluation-indicators","dir":"Articles","previous_headings":"Fit the Data","what":"Evaluation indicators","title":"Applications III: HGDP Data Set","text":"  store result result_HGDP_evaluate.RData.","code":"loglikelihood_HGDP_em <- vector() error_HGDP_em <- vector() for (i in 2:15) {   result <- get(paste(\"result_HGDP_em_K\", i, sep=\"\"))   loglikelihood_HGDP_em <- c(loglikelihood_HGDP_em,                               result$L[length(result$L)])   error_HGDP_em <- c(error_HGDP_em,                       psd_error(data_HGDP, result)) } rm(result) rm(i) loglikelihood_HGDP_sqp <- vector() error_HGDP_sqp <- vector() for (i in 2:15) {   result <- get(paste(\"result_HGDP_sqp_K\", i, sep=\"\"))   loglikelihood_HGDP_sqp <- c(loglikelihood_HGDP_sqp,                                result$L[length(result$L)])   error_HGDP_sqp <- c(error_HGDP_sqp,                        psd_error(data_HGDP, result)) } rm(result) rm(i) ELBO_HGDP_vi <- vector() loglikelihood_HGDP_vi <- vector() error_HGDP_vi <- vector() for (i in 2:15) {   result <- get(paste(\"result_HGDP_vi_K\", i, sep=\"\"))   ELBO_HGDP_vi <- c(ELBO_HGDP_vi,                      result$L[length(result$L)])   loglikelihood_HGDP_vi <- c(loglikelihood_HGDP_vi,                               psd_loglikelihood(data_HGDP, result))   error_HGDP_vi <- c(error_HGDP_vi,                       psd_error(data_HGDP, result)) } rm(result) rm(i) ind_J <- sample(2, ncol(data_HGDP), replace = TRUE, prob = c(1 - 5e-2, 5e-2)) ind_I <- sample(2, nrow(data_HGDP), replace = TRUE, prob = c(1 - 1e-1, 1e-1)) data_HGDP_val <- data_HGDP[ind_I == 2, ind_J == 2] loglikelihood_HGDP_svi <- vector() for (i in 2:15) {   P_val <- get(paste(\"result_HGDP_svi_K\", i, \"_sample\", sep=\"\"))$P[ind_I == 2, ]   loglikelihood_HGDP_svi <- c(loglikelihood_HGDP_svi,                                psd_loglikelihood_svi(data_HGDP_val, i, P_val)) } rm(ind_J) rm(ind_I) rm(data_HGDP_val) rm(P_val) rm(i)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"choose-k","dir":"Articles","previous_headings":"","what":"Choose K","title":"Applications III: HGDP Data Set","text":"  import data directly.   Criteria choosing K: obvious gap indicators, smaller K preferred.    notice log-likelihood curves EM SQP continuous upward trend, due fact prior distribution constraint, prone overfitting. log-likelihood curves EM SQP slow K equals 7.   log-likelihood curve VI flattens K equals 6, shows optimal K 8 11.    log-likelihood curve SVI relatively irregular three reasons. First, use different training validation sets fit different K. Although finally fixed validation set calculating log-likelihood validation set, based assumption data equivalent. Second, convergence criterion may relatively loose, resulting cases really converge optimal value. Third, sensitivity algorithm initial value leads large errors single measurement.   log-likelihood curve SVI shows optimal K 11 14, 8, 9, 10, 11 good choices K.    error curves EM, SQP VI almost identical log-likelihood curves EM, SQP VI. error function computed based entire training set. way make meaningful compute error function validation set (involved training) evaluate algorithm using either normal validation cross validation.    ELBO curve VI shows curve oscillating K equals 7.   conclusion, note K around 7, fit already well. optimal K reached around 11, structure diagram, populations appear redundant time.","code":"load(system.file(\"extdata\", \"result_HGDP_evaluate.RData\", package = \"AwesomePackage\", mustWork = TRUE)) plot_index_vs_K(list(loglikelihood_HGDP_em, loglikelihood_HGDP_sqp, loglikelihood_HGDP_vi),                  c(\"em\", \"sqp\", \"vi\"), index.id = \"loglik\") plot_index_vs_K(list(loglikelihood_HGDP_svi),                  \"svi\", index.id = \"loglik\") plot_index_vs_K(list(error_HGDP_em, error_HGDP_sqp, error_HGDP_vi),                  c(\"em\", \"sqp\", \"vi\"), index.id = \"error\") plot_index_vs_K(list(ELBO_HGDP_vi),                  \"vi\", index.id = \"elbo\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"full-data","dir":"Articles","previous_headings":"","what":"Full Data","title":"Applications III: HGDP Data Set","text":"  fit complete data relatively good K using SVI algorithm.   addition, iterated million times case best K (equals 7 11).   store result result_HGDP_full.RData. import data directly.    best K (equals 7 11), draw subtle structures. can compare results articles (Li et al. 2008; Raj, Stephens, Pritchard 2014; Gopalan et al. 2016), structure diagram almost .","code":"result_HGDP_svi_K7_full <- psd_fit_svi(t(data_HGDP_full), 7,                                        1e-5, 1e+6, 1e+4, 5,                                        100, 2000,                                        5e-3, 1e-1,                                        1, 0.5) # [======>----------------------------------------------------] 120000/1e+06 (24m) result_HGDP_svi_K8_full <- psd_fit_svi(t(data_HGDP_full), 8,                                        1e-5, 1e+6, 1e+4, 5,                                        100, 2000,                                        5e-3, 1e-1,                                        1, 0.5) # [======>----------------------------------------------------] 120000/1e+06 (25m) result_HGDP_svi_K9_full <- psd_fit_svi(t(data_HGDP_full), 9,                                        1e-5, 1e+6, 1e+4, 5,                                        100, 2000,                                        5e-3, 1e-1,                                        1, 0.5) # [==================>----------------------------------------] 320000/1e+06 ( 1h) result_HGDP_svi_K10_full <- psd_fit_svi(t(data_HGDP_full), 10,                                        1e-5, 1e+6, 1e+4, 5,                                        100, 2000,                                        5e-3, 1e-1,                                        1, 0.5) # [==============>--------------------------------------------] 250000/1e+06 ( 1h) result_HGDP_svi_K11_full <- psd_fit_svi(t(data_HGDP_full), 11,                                        1e-5, 1e+6, 1e+4, 5,                                        100, 2000,                                        5e-3, 1e-1,                                        1, 0.5) # [=====>-----------------------------------------------------] 110000/1e+06 (29m) result_HGDP_svi_K7_full_million <- psd_fit_svi(t(data_HGDP_full), 7,                                                1e-9, 1e+6, 1e+5, 10,                                                100, 2000,                                                5e-3, 1e-1,                                                1, 0.5) # [============================================================] 1e+06/1e+06 ( 3h) result_HGDP_svi_K11_full_million <- psd_fit_svi(t(data_HGDP_full), 11,                                                1e-9, 1e+6, 1e+5, 10,                                                100, 2000,                                                5e-3, 1e-1,                                                1, 0.5) # [============================================================] 1e+06/1e+06 ( 4h) load(system.file(\"extdata\", \"result_HGDP_full.RData\", package = \"AwesomePackage\", mustWork = TRUE)) label <- rownames(data_HGDP) lpop <- unlist(map_HGDP[1]) spop <- unlist(map_HGDP[2]) indiv <- unlist(map_HGDP[3]) plot_structure(result_HGDP_svi_K7_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP (full) | Method: SVI | K: 7\") plot_structure(result_HGDP_svi_K8_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP (full) | Method: SVI | K: 8\") plot_structure(result_HGDP_svi_K9_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP (full) | Method: SVI | K: 9\") plot_structure(result_HGDP_svi_K10_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP (full) | Method: SVI | K: 10\") plot_structure(result_HGDP_svi_K11_full$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP (full) | Method: SVI | K: 11\") plot_structure(result_HGDP_svi_K7_full_million$P,                 label = label, map.indiv = indiv, map.pop = spop, gap = 2, font.size = 6,                 title = \"Data Set: HGDP (full) | Method: SVI (1e+6 interations) | K: 7\") plot_structure(result_HGDP_svi_K11_full_million$P,                 label = label, map.indiv = indiv, map.pop = spop, gap = 2, font.size = 6,                 title = \"Data Set: HGDP (full) | Method: SVI (1e+6 interations) | K: 11\")"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"convergence-accuracy","dir":"Articles","previous_headings":"Algorithm Evaluation","what":"Convergence accuracy","title":"Applications III: HGDP Data Set","text":"  suitable K, SVI algorithm SQP algorithm perform best terms convergence accuracy, followed VI algorithm finally EM algorithm. See Get started AwesomePackage details.   unknown K, due lack prior constraints, EM algorithm SQP algorithm prone overfitting population number redundant. can see clearly Appendix B. Therefore, better use VI algorithm SVI algorithm select appropriate K.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"convergence-efficiency","dir":"Articles","previous_headings":"Algorithm Evaluation","what":"Convergence efficiency","title":"Applications III: HGDP Data Set","text":"  addition measuring accuracy convergence, still need consider efficiency convergence. two indicators measure convergence efficiency, convergence speed (number iterations required achieve convergence) convergence time (time required single iteration). can plot convergence time using code , can see convergence speed plots Appendix .    EM algorithm poor terms convergence time convergence speed, convergence time increases rapidly increase K.   Although SQP algorithm good performance terms convergence speed, convergence time unaccelerated SQP algorithm extremely slow, increases rapidly increase K.   VI algorithm similar convergence speed EM algorithm (poor performance), terms convergence time, VI algorithm excellent performance, especially increase K, required time increases slowly.   Due different principles, consider convergence time SVI algorithm. Although performance convergence time SVI algorithm poor small data sets, time SVI algorithm almost related length single sampling (number individuals), say, complete data sets, convergence time SVI almost unchanged. means SVI irreplaceable advantages large data sets. Meanwhile, similar VI algorithm, change convergence time SVI algorithm relatively insensitive K. way, compared algorithms, convergence time SVI algorithm irregular due randomness sampling.","code":"L <- list(c(1,3,4,9,13,27,15,25,34,60,44,60,60,60),           c(1,2,4,7,8,15,25,59,35,84,80,120,103,120),           c(3,1,3,5,5,5,6,7,8,9,8,9,14,12),           c(8,16,28,22,40,20,17,31,60,26,41,60,21,120)) plot_index_vs_K(L, c(\"em\", \"sqp\", \"vi\", \"svi\"), index.id = \"time\",                  title = \"Data Set: HGDP\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"algorithm-selection-criteria","dir":"Articles","previous_headings":"Algorithm Evaluation","what":"Algorithm selection criteria","title":"Applications III: HGDP Data Set","text":"  conclusion, consider algorithm accuracy algorithm efficiency.   small data sets, can get good results using VI directly. can first use VI algorithm reach vicinity optimal value, use SQP algorithm improve convergence accuracy. reason SQP algorithm directly used unaccelerated SQP algorithm inefficient SQP algorithm extremely easy converge local minima.   large data sets, use SVI algorithm without question.   course, K unknown, pick K first, way .","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"AppendixA","dir":"Articles","previous_headings":"","what":"Appendix A","title":"Applications III: HGDP Data Set","text":"","code":"load(system.file(\"extdata\", \"result_HGDP_em.RData\", package = \"AwesomePackage\", mustWork = TRUE)) load(system.file(\"extdata\", \"result_HGDP_sqp.RData\", package = \"AwesomePackage\", mustWork = TRUE)) load(system.file(\"extdata\", \"result_HGDP_vi.RData\", package = \"AwesomePackage\", mustWork = TRUE)) load(system.file(\"extdata\", \"result_HGDP_svi.RData\", package = \"AwesomePackage\", mustWork = TRUE)) plot_loss(list(result_HGDP_em_K2$Loss[-1], result_HGDP_sqp_K2$Loss[-1],                 result_HGDP_vi_K2$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 2\") plot_loss(list(result_HGDP_svi_K2_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 2\") plot_loss(list(result_HGDP_em_K3$Loss[-1], result_HGDP_sqp_K3$Loss[-1],                 result_HGDP_vi_K3$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 3\") plot_loss(list(result_HGDP_svi_K3_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 3\") plot_loss(list(result_HGDP_em_K4$Loss[-1], result_HGDP_sqp_K4$Loss[-1],                 result_HGDP_vi_K4$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 4\") plot_loss(list(result_HGDP_svi_K4_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 4\") plot_loss(list(result_HGDP_em_K5$Loss[-1], result_HGDP_sqp_K5$Loss[-1],                 result_HGDP_vi_K5$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 5\") plot_loss(list(result_HGDP_svi_K5_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 5\") plot_loss(list(result_HGDP_em_K6$Loss[-1], result_HGDP_sqp_K6$Loss[-1],                 result_HGDP_vi_K6$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 6\") plot_loss(list(result_HGDP_svi_K6_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 6\") plot_loss(list(result_HGDP_em_K7$Loss[-1], result_HGDP_sqp_K7$Loss[-1],                 result_HGDP_vi_K7$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 7\") plot_loss(list(result_HGDP_svi_K7_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 7\") plot_loss(list(result_HGDP_em_K8$Loss[-1], result_HGDP_sqp_K8$Loss[-1],                 result_HGDP_vi_K8$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 8\") plot_loss(list(result_HGDP_svi_K8_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 8\") plot_loss(list(result_HGDP_em_K9$Loss[-1], result_HGDP_sqp_K9$Loss[-1],                 result_HGDP_vi_K9$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 9\") plot_loss(list(result_HGDP_svi_K9_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 9\") plot_loss(list(result_HGDP_em_K10$Loss[-1], result_HGDP_sqp_K10$Loss[-1],                 result_HGDP_vi_K10$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 10\") plot_loss(list(result_HGDP_svi_K10_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 10\") plot_loss(list(result_HGDP_em_K11$Loss[-1], result_HGDP_sqp_K11$Loss[-1],                 result_HGDP_vi_K11$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 11\") plot_loss(list(result_HGDP_svi_K11_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 11\") plot_loss(list(result_HGDP_em_K12$Loss[-1], result_HGDP_sqp_K12$Loss[-1],                 result_HGDP_vi_K12$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 12\") plot_loss(list(result_HGDP_svi_K12_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 12\") plot_loss(list(result_HGDP_em_K13$Loss[-1], result_HGDP_sqp_K13$Loss[-1],                 result_HGDP_vi_K13$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 13\") plot_loss(list(result_HGDP_svi_K13_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 13\") plot_loss(list(result_HGDP_em_K14$Loss[-1], result_HGDP_sqp_K14$Loss[-1],                 result_HGDP_vi_K14$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 14\") plot_loss(list(result_HGDP_svi_K14_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 14\") plot_loss(list(result_HGDP_em_K15$Loss[-1], result_HGDP_sqp_K15$Loss[-1],                 result_HGDP_vi_K15$Loss[-1]), c(\"em\", \"em & sqp\", \"vi\"), 10,            title = \"Data Set: HGDP | K: 15\") plot_loss(list(result_HGDP_svi_K15_sample$Loss), \"svi\", 1e+4,            title = \"Data Set: HGDP | K: 15\")"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"em-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"EM algorithm","title":"Applications III: HGDP Data Set","text":"","code":"plot_structure(result_HGDP_em_K2$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 2\") plot_structure(result_HGDP_em_K3$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 3\") plot_structure(result_HGDP_em_K4$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 4\") plot_structure(result_HGDP_em_K5$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 5\") plot_structure(result_HGDP_em_K6$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 6\") plot_structure(result_HGDP_em_K7$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 7\") plot_structure(result_HGDP_em_K8$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 8\") plot_structure(result_HGDP_em_K9$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 9\") plot_structure(result_HGDP_em_K10$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 10\") plot_structure(result_HGDP_em_K11$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 11\") plot_structure(result_HGDP_em_K12$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 12\") plot_structure(result_HGDP_em_K13$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 13\") plot_structure(result_HGDP_em_K14$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 14\") plot_structure(result_HGDP_em_K15$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: EM | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"sqp-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"SQP algorithm","title":"Applications III: HGDP Data Set","text":"","code":"plot_structure(result_HGDP_sqp_K2$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 2\") plot_structure(result_HGDP_sqp_K3$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 3\") plot_structure(result_HGDP_sqp_K4$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 4\") plot_structure(result_HGDP_sqp_K5$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 5\") plot_structure(result_HGDP_sqp_K6$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 6\") plot_structure(result_HGDP_sqp_K7$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 7\") plot_structure(result_HGDP_sqp_K8$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 8\") plot_structure(result_HGDP_sqp_K9$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 9\") plot_structure(result_HGDP_sqp_K10$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 10\") plot_structure(result_HGDP_sqp_K11$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 11\") plot_structure(result_HGDP_sqp_K12$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 12\") plot_structure(result_HGDP_sqp_K13$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 13\") plot_structure(result_HGDP_sqp_K14$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 14\") plot_structure(result_HGDP_sqp_K15$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SQP | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"vi-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"VI algorithm","title":"Applications III: HGDP Data Set","text":"","code":"plot_structure(result_HGDP_vi_K2$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 2\") plot_structure(result_HGDP_vi_K3$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 3\") plot_structure(result_HGDP_vi_K4$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 4\") plot_structure(result_HGDP_vi_K5$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 5\") plot_structure(result_HGDP_vi_K6$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 6\") plot_structure(result_HGDP_vi_K7$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 7\") plot_structure(result_HGDP_vi_K8$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 8\") plot_structure(result_HGDP_vi_K9$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 9\") plot_structure(result_HGDP_vi_K10$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 10\") plot_structure(result_HGDP_vi_K11$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 11\") plot_structure(result_HGDP_vi_K12$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 12\") plot_structure(result_HGDP_vi_K13$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 13\") plot_structure(result_HGDP_vi_K14$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 14\") plot_structure(result_HGDP_vi_K15$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: VI | K: 15\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/12_application_hgdp.html","id":"svi-algorithm-1","dir":"Articles","previous_headings":"Appendix B","what":"SVI algorithm","title":"Applications III: HGDP Data Set","text":"","code":"plot_structure(result_HGDP_svi_K2_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 2\") plot_structure(result_HGDP_svi_K3_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 3\") plot_structure(result_HGDP_svi_K4_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 4\") plot_structure(result_HGDP_svi_K5_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 5\") plot_structure(result_HGDP_svi_K6_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 6\") plot_structure(result_HGDP_svi_K7_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 7\") plot_structure(result_HGDP_svi_K8_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 8\") plot_structure(result_HGDP_svi_K9_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 9\") plot_structure(result_HGDP_svi_K10_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 10\") plot_structure(result_HGDP_svi_K11_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 11\") plot_structure(result_HGDP_svi_K12_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 12\") plot_structure(result_HGDP_svi_K13_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 13\") plot_structure(result_HGDP_svi_K14_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 14\") plot_structure(result_HGDP_svi_K15_sample$P,                 label = label, map.indiv = indiv, map.pop = lpop, gap = 5,                 title = \"Data Set: HGDP | Method: SVI | K: 15\")"},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"psd-model-and-data","dir":"Articles","previous_headings":"Fit PSD model","what":"PSD model and data","title":"AwesomePackage: Quick Start","text":"consider sample data 1000 Genomes Project (TGP) use PSD model fit data. import pre-trained results directly.","code":"load(system.file(\"extdata\", \"result_fit_psd.RData\", package = \"AwesomePackage\", mustWork = TRUE))"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"fit-psd-model-by-em-algorithm","dir":"Articles","previous_headings":"Fit PSD model","what":"Fit PSD model by EM algorithm","title":"AwesomePackage: Quick Start","text":"fit PSD model EM algorithm, use loss function stopping criterion. EM algorithm converges slowly. takes 450 EM iterations reach predetermined accuracy. plot loss function number iterations using package ggplot2, loss function records 10 iterations.  plot ancestral proportions individuals using package ggplot2. fitting result EM algorithm accurate.  measure prediction accuracy dataset maximum likelihood function deviance residuals.","code":"result_TGP_em <- psd_fit_em(data_TGP, 3, 1e-5, 500) # [=========================================================>------] 450/500 ( 3m) L <- result_TGP_em$Loss plot_loss(list(L), \"em\", 10) P <- result_TGP_em$P plot_structure(P) L[length(L)] ## [1] -0.5971432 psd_error(data_TGP, result_TGP_em) ## [1] 0.3374755"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"fit-psd-model-by-sqp-algorithm","dir":"Articles","previous_headings":"Fit PSD model","what":"Fit PSD model by SQP algorithm","title":"AwesomePackage: Quick Start","text":"fit PSD model SQP algorithm, use loss function stopping criterion. Although SQP algorithm converges fast, easy converge local optimal value. prevent bad scenario, start 100 EM iterations, need 40 SQP iterations reach accuracy requirement. plot loss function number iterations using package ggplot2, loss function records 10 iterations.  plot ancestral proportions individuals using package ggplot2. Notice fitting result SQP algorithm excellent.  measure prediction accuracy dataset maximum likelihood function deviance residuals.","code":"result_TGP_sqp <- psd_fit_sqp(data_TGP, 3, 1e-5, 50, 100) # [================================================================] 100/100 (35s) # [====================================================>-------------] 40/50 ( 1m) L <- result_TGP_sqp$Loss plot_loss(list(L), \"em & sqp\", 10) P <- result_TGP_sqp$P plot_structure(P) L[length(L)] ## [1] -0.5969287 psd_error(data_TGP, result_TGP_sqp) ## [1] 0.3372611"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"fit-psd-model-by-vi-algorithm","dir":"Articles","previous_headings":"Fit PSD model","what":"Fit PSD model by VI algorithm","title":"AwesomePackage: Quick Start","text":"fit PSD model VI algorithm, use loss function stopping criterion. Similar EM algorithm, convergence VI algorithm also relatively slow, 490 iterations needed reach accuracy requirement. plot loss function number iterations using package ggplot2, loss function records 10 iterations.  plot ancestral proportions individuals using package ggplot2. fitting result much better EM algorithm.  measure prediction accuracy dataset evidence lower bound (ELBO), maximum likelihood function deviance residuals.","code":"result_TGP_vi <- psd_fit_vi(data_TGP, 3, 1e-5, 500) # [==============================================================>-] 490/500 ( 2m) L <- result_TGP_vi$Loss plot_loss(list(L), \"vi\", 10) P <- result_TGP_vi$P plot_structure(P) L[length(L)] ## [1] -0.6103088 psd_loglikelihood(data_TGP, result_TGP_vi) ## [1] -0.59751 psd_error(data_TGP, result_TGP_vi) ## [1] 0.3378423"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"fit-psd-model-by-svi-algorithm","dir":"Articles","previous_headings":"Fit PSD model","what":"Fit PSD model by SVI algorithm","title":"AwesomePackage: Quick Start","text":"fit PSD model SVI algorithm, use loss function stopping criterion. completed fitting 13 min, little longer previous three algorithms. Although SVI algorithm known fast speed, dataset large number individuals. can predicted complete TGP data, SVI algorithm still needs time, time algorithms greatly increased. Perhaps time algorithms similar data similar TGP data size, number individuals large, performance SVI algorithm much better, also superiority SVI algorithm. plot loss function number iterations using package ggplot2, loss function records 10,000 iterations. natural thing use change loss function stopping criterion, can seen , loss function validation set necessarily monotonic. sampling interval large, loss function oscillate near optimal value, cycle finished. sampling interval small, loss function almost constant, resulting premature exit loop. However, proper sampling intervals difficult find. simply added maximum number iterations (case, 50,000) stopping criterion, loss function used post-hoc metric.  plot ancestral proportions individuals using package ggplot2. convergence accuracy SVI algorithm also good.  measure prediction accuracy dataset maximum likelihood function validation set.","code":"result_TGP_svi <- psd_fit_svi(data_TGP, 3,                               1e-5, 5e+5, 1e+4, 3,                               100, 2000,                               5e-2, 1e-1,                               1, 0.5) # [============>----------------------------------------------] 110000/5e+05 (13m) L <- result_TGP_svi$Loss plot_loss(list(L), \"svi\", 1e+4) P <- result_TGP_svi$P plot_structure(P) result_TGP_svi$MaxLoss ## [1] -0.614379"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"structure-plot","dir":"Articles","previous_headings":"","what":"Structure plot","title":"AwesomePackage: Quick Start","text":"analyze structure diagrams four algorithms TGP HGDP. import pre-trained results directly.","code":"load(system.file(\"extdata\", \"result_structure_plot.RData\", package = \"AwesomePackage\", mustWork = TRUE))"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"tgp","dir":"Articles","previous_headings":"Structure plot","what":"TGP","title":"AwesomePackage: Quick Start","text":"Large populations.  Small populations.","code":"result_TGP <- psd_fit_vi(data_TGP, 4, 1e-5, 2000) # [=========================>-------------------------------------] 840/2000 ( 4m) P <- result_TGP$P label <- rownames(data_TGP) lpop <- unlist(map_TGP[1]) spop <- unlist(map_TGP[2]) indiv <- unlist(map_TGP[3]) plot_structure(P, label = label, map.indiv = indiv, map.pop = lpop, gap = 5) plot_structure(P, label = label, map.indiv = indiv, map.pop = spop, gap = 5)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"hgdp","dir":"Articles","previous_headings":"Structure plot","what":"HGDP","title":"AwesomePackage: Quick Start","text":"Large populations.  Small populations.","code":"result_HGDP <- psd_fit_vi(data_HGDP, 7, 1e-5, 2000) # [=============================>---------------------------------] 940/2000 ( 5m) P <- result_HGDP$P label <- rownames(data_HGDP) lpop <- unlist(map_HGDP[1]) spop <- unlist(map_HGDP[2]) indiv <- unlist(map_HGDP[3]) plot_structure(P, label = label, map.indiv = indiv, map.pop = lpop, gap = 5) plot_structure(P, label = label, map.indiv = indiv, map.pop = spop, gap = 3, font.size = 5)"},{"path":"https://jonathonchow.github.io/AwesomePackage/articles/AwesomePackage.html","id":"choose-hyper-parameter-k","dir":"Articles","previous_headings":"","what":"Choose hyper-parameter K","title":"AwesomePackage: Quick Start","text":"fit different hyperparameters K respectively, select K makes indices optimal. conduct experiments TPG HGDP datasets different algorithms separately. See Articles AwesomePackage details.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jonathon Chow. Author, maintainer.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chow J (2022). AwesomePackage: Infer ancestry PSD model fit PSD model algorithms. https://github.com/JONATHONCHOW/AwesomePackage, https://jonathonchow.github.io/AwesomePackage/.","code":"@Manual{,   title = {AwesomePackage: Infer ancestry with PSD model and fit PSD model with some algorithms},   author = {Jonathon Chow},   year = {2022},   note = {https://github.com/JONATHONCHOW/AwesomePackage, https://jonathonchow.github.io/AwesomePackage/}, }"},{"path":"https://jonathonchow.github.io/AwesomePackage/index.html","id":"awesomepackage-","dir":"","previous_headings":"","what":"Infer ancestry with PSD model and fit PSD model with some algorithms","title":"Infer ancestry with PSD model and fit PSD model with some algorithms","text":"goal AwesomePackage infer ancestry PSD model fit PSD model algorithms. use classical PSD model ancestor inference, widely used, STRUCTURE (Pritchard et al. 2000, MCMC), FRAPPE (Tang et al. 2005, EM), ADMIXTURE (Alexander et al. 2009, SQP), fastSTRUCTURE (Raj et al. 2014, VI), TeraStructure (Gopalan et al. 2017, SVI). illustrate close relationship PSD model, Poisson NMF model, multinomial topic model LDA model, can optimize algorithm. use Expectation-Maximization algorithm (EM), sequential quadratic programming algorithm (SQP), variational inference algorithm (VI) stochastic variational inference algorithm (SVI) fit model, illustrate relationships differences algorithms simulation experiments real data experiments.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Infer ancestry with PSD model and fit PSD model with some algorithms","text":"can install development version AwesomePackage GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"JONATHONCHOW/AwesomePackage\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Infer ancestry with PSD model and fit PSD model with some algorithms","text":"can check theories examples Articles AwesomePackage.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Infer ancestry with PSD model and fit PSD model with some algorithms","text":"can use following code see AwesomePackage successfully installed. can refer Reference AwesomePackage use functions, can fun ancestry inference!","code":"library(AwesomePackage) hello_world() #> [1] \"Data science is fantastic!\""},{"path":"https://jonathonchow.github.io/AwesomePackage/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 AwesomePackage authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/data_HGDP.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data from the Human Genome Diversity Project — data_HGDP","title":"Sample data from the Human Genome Diversity Project — data_HGDP","text":"group scientists Stanford University collaborated large study understand genetic diversity human populations. analyzed genomic DNA 1,043 individuals around world, determining genotypes 650,000 SNP loci, Illumina BeadStation technology. Genomic DNA samples fully-consenting individuals collected Human Genome Diversity Project (HGDP), collaboration Centre Etude Polymorphism Humain (CEPH) Paris. collection tested referred \"HGDP-CEPH Human Genome Diversity Cell Line Panel\". represent 51 different populations Africa, Europe, Middle East, South Central Asia, East Asia, Oceania Americas.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/data_HGDP.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data from the Human Genome Diversity Project — data_HGDP","text":"data_HGDP 942 x 50000 matrix.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/data_HGDP.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sample data from the Human Genome Diversity Project — data_HGDP","text":"https://cephb.fr/en/hgdp_panel.php","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/data_TGP.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data from the 1000 Genomes Project — data_TGP","title":"Sample data from the 1000 Genomes Project — data_TGP","text":"1000 Genomes Project (TGP) created catalogue common human genetic variation, using openly consented samples people declared healthy. reference data resources generated project remain heavily used biomedical science community. International Genome Sample Resource (IGSR) maintains shares human genetic variation resources built 1000 Genomes Project. also update resources current reference assembly, add new data sets generated 1000 Genomes Project samples add data projects working openly consented samples.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/data_TGP.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data from the 1000 Genomes Project — data_TGP","text":"data_TGP 1092 x 50000 matrix.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/data_TGP.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sample data from the 1000 Genomes Project — data_TGP","text":"https://www.internationalgenome.org/","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/hello_world.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello world — hello_world","title":"Hello world — hello_world","text":"Hello world add \"AwesomePackage\" NAMESPACE.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/hello_world.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello world — hello_world","text":"","code":"hello_world()"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/hello_world.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hello world — hello_world","text":"string \"Data science fantastic!\".","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/hello_world.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello world — hello_world","text":"","code":"hello_world() #> [1] \"Data science is fantastic!\""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/map_HGDP.html","id":null,"dir":"Reference","previous_headings":"","what":"Corresponding tables for individuals and populations of the HGDP dataset — map_HGDP","title":"Corresponding tables for individuals and populations of the HGDP dataset — map_HGDP","text":"map_HGDP gives corresponding relationship among individuals, small populations large populations. plot_structure uses relationship group data draw structure plot.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/map_HGDP.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Corresponding tables for individuals and populations of the HGDP dataset — map_HGDP","text":"map_HGDP table three columns. Superpop Large populations, Asians, Africans, Europeans. Pop Small populations, Chinese, British, Norwegian. Indiv Individuals.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/map_TGP.html","id":null,"dir":"Reference","previous_headings":"","what":"Corresponding tables for individuals and populations of the TGP dataset — map_TGP","title":"Corresponding tables for individuals and populations of the TGP dataset — map_TGP","text":"map_TGP gives corresponding relationship among individuals, small populations large populations. plot_structure uses relationship group data draw structure plot.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/map_TGP.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Corresponding tables for individuals and populations of the TGP dataset — map_TGP","text":"map_TGP table three columns. Superpop Large populations, Asians, Africans, Europeans. Pop Small populations, Chinese, British, Norwegian. Indiv Individuals.","code":""},{"path":[]},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_index_vs_K.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the relationship between index and K — plot_index_vs_K","title":"Plot the relationship between index and K — plot_index_vs_K","text":"Draw diagram relationship index K using package ggplot2. index can loglikelihood, error, ELBO, time.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_index_vs_K.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the relationship between index and K — plot_index_vs_K","text":"","code":"plot_index_vs_K(   L,   methods,   index.id = c(\"loglik\", \"error\", \"elbo\", \"time\"),   start.point = 2,   colors = c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"),   linetypes = \"solid\",   linesizes = 0.5,   shapes = 19,   fills = \"white\",   theme = function() theme_cowplot(12),   title = NULL )"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_index_vs_K.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the relationship between index and K — plot_index_vs_K","text":"L list element vector index respect K. methods vector length L element name fitting algorithm, \"em\", \"sqp\", \"vi\", \"svi\". index.id Choose index. one \"loglik\", \"error\", \"elbo\", \"time\". start.point initial point K. colors colors used draw curves. linetypes line types used draw curves. linesizes line sizes used draw curves. shapes shapes used draw points. fills fill colors used draw points. theme ggplot2 theme. title Title plot.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_index_vs_K.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the relationship between index and K — plot_index_vs_K","text":"ggplot object.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_index_vs_K.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the relationship between index and K — plot_index_vs_K","text":"","code":"L <- list(c(-50,-20,-10,-1,-0.5), c(-30,-5,-1,-0.1)) plot_index_vs_K(L, c(\"fun\",\"more fun\"), index.id = \"loglik\")  L <- list(c(0.1,0.5,0.7,1.2), c(1.6,0.2,0.8,1.5,2.4)) plot_index_vs_K(L, c(\"fun\",\"more fun\"), index.id = \"error\")  L <- list(c(-10,-2,-0.5,-0.1), c(-5,-1,-0.1)) plot_index_vs_K(L, c(\"fun\",\"more fun\"), index.id = \"elbo\")  L <- list(c(10,15,20), c(12,18,30,32)) plot_index_vs_K(L, c(\"fun\",\"more fun\"), index.id = \"time\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the loss function — plot_loss","title":"Plot the loss function — plot_loss","text":"Plot loss function number iterations using package ggplot2.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the loss function — plot_loss","text":"","code":"plot_loss(   L,   methods,   sample.rate,   epsilon = 0.01,   colors = c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"),   linetypes = \"solid\",   linesizes = 0.5,   shapes = 19,   fills = \"white\",   theme = function() theme_cowplot(12),   title = NULL )"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the loss function — plot_loss","text":"L list element vector loss functions respect number iterations. methods vector length L element name fitting algorithm, \"em\", \"sqp\", \"vi\", \"svi\". sample.rate sampling rate loss function. epsilon small, positive number added vertical axis logarithmic scale -emphasize small differences. colors colors used draw loss curves. linetypes line types used draw loss curves. linesizes line sizes used draw loss curves. shapes shapes used draw points iterations. fills fill colors used draw points iterations. theme ggplot2 theme. title Title plot, \"K = 2\", \"K = 3\".","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the loss function — plot_loss","text":"ggplot object.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the loss function — plot_loss","text":"","code":"L <- list(c(-100,-20,-10,-1,-0.5,-0.3,-0.1), c(-30,-5,-1,-0.1,-0.05)) plot_loss(L, c(\"fun\",\"more fun\"), 1)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_structure.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the population proportion — plot_structure","title":"Plot the population proportion — plot_structure","text":"Plot population proportion individuals using package ggplot2.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_structure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the population proportion — plot_structure","text":"","code":"plot_structure(   P,   pops = NULL,   label = NULL,   map.indiv = NULL,   map.pop = NULL,   gap = NULL,   colors = c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#EE2C2C\", \"#CC79A7\",     \"#8968CD\", \"#FF83FA\", \"#EECFA1\", \"#A52A2A\", \"#4169E1\", \"#FFFF00\", \"#BFEFFF\",     \"#FF1493\"),   font.size = 9,   title = NULL,   subtitle = NULL )"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_structure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the population proportion — plot_structure","text":"P proportion matrix. pops Population order options. label original order individuals. option data needs grouped. map.indiv new order individuals. option data needs grouped. map.pop order populations. option data needs grouped. gap Gaps groups. option data needs grouped. colors Theme color options. font.size Font size used plot. title Title plot, \"EM\", \"SQP\", \"VI\", \"SVI\". subtitle Subtitle plot, \"K = 2\", \"K = 3\".","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_structure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the population proportion — plot_structure","text":"ggplot object.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/plot_structure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the population proportion — plot_structure","text":"","code":"P <- matrix(c(0.5,0.3,0.8, 0.5,0.7,0.2), 3, 2) plot_structure(P, title = \"FUN\")"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the prediction error — psd_error","title":"Compute the prediction error — psd_error","text":"Compute deviance residuals binomial model averaged entries prediction error.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the prediction error — psd_error","text":"","code":"psd_error(G, result)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the prediction error — psd_error","text":"G x J matrix counts; entries G taken {0,1,2}. result Output psd_fit_em, psd_fit_sqp, psd_fit_vi.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the prediction error — psd_error","text":"value indicates accuracy prediction.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the prediction error — psd_error","text":"","code":"G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) result <- psd_fit_em(G, 2, 1e-5, 10) psd_error(G, result) #> [1] 0.1686011"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_em.html","id":null,"dir":"Reference","previous_headings":"","what":"Use EM algorithm to fit PSD model — psd_fit_em","title":"Use EM algorithm to fit PSD model — psd_fit_em","text":"Fit PSD model EM algorithm, use loss function stopping criterion.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_em.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use EM algorithm to fit PSD model — psd_fit_em","text":"","code":"psd_fit_em(G, K, epsilon = 1e-05, maxiter = 500)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_em.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use EM algorithm to fit PSD model — psd_fit_em","text":"G x J matrix counts; entries G taken {0,1,2}. K integer 2 greater giving matrix rank. epsilon Convergence criterion. maxiter maximum number iterations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_em.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use EM algorithm to fit PSD model — psd_fit_em","text":"List following parameters: P population scale matrix individuals. F gene scale matrix populations. Loss vector represents value loss function records 10 iterations. Iterations integer represents number iterations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_em.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use EM algorithm to fit PSD model — psd_fit_em","text":"","code":"G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) psd_fit_em(G, 2, 1e-5, 10) #> $P #>            [,1]       [,2] #> [1,] 0.98716323 0.01283677 #> [2,] 0.02402906 0.97597094 #> [3,] 0.70213453 0.29786547 #>  #> $F #>            [,1]       [,2]         [,3]         [,4]         [,5] #> [1,] 0.26133691 0.02278575 0.5717675706 1.424245e-11 3.069712e-01 #> [2,] 0.02562684 0.99999886 0.0007086483 4.232162e-01 4.607535e-10 #>  #> $Loss #> [1] -0.7195729 #>  #> $Iterations #> [1] 10 #>"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_sqp.html","id":null,"dir":"Reference","previous_headings":"","what":"Use SQP algorithm to fit PSD model — psd_fit_sqp","title":"Use SQP algorithm to fit PSD model — psd_fit_sqp","text":"Fit PSD model SQP algorithm, use loss function stopping criterion.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_sqp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use SQP algorithm to fit PSD model — psd_fit_sqp","text":"","code":"psd_fit_sqp(G, K, epsilon = 1e-05, maxiter = 50, initem = 100)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_sqp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use SQP algorithm to fit PSD model — psd_fit_sqp","text":"G x J matrix counts; entries G taken {0,1,2}. K integer 2 greater giving matrix rank. epsilon Convergence criterion. maxiter maximum number iterations. initem number iterations using EM algorithm initialization.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_sqp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use SQP algorithm to fit PSD model — psd_fit_sqp","text":"List following parameters: P population scale matrix individuals. F gene scale matrix populations. Loss vector represents value loss function records 10 iterations. Iterations integer represents number iterations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_sqp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use SQP algorithm to fit PSD model — psd_fit_sqp","text":"","code":"G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) psd_fit_sqp(G, 2, 1e-5, 10, 10) #> $P #>             [,1]        [,2] #> [1,] 0.000000001 0.999999999 #> [2,] 0.999999999 0.000000001 #> [3,] 0.310834358 0.689165642 #>  #> $F #>             [,1]  [,2]        [,3]        [,4]        [,5] #> [1,] 0.000000001 1e+00 0.000000001 0.413499269 0.000000001 #> [2,] 0.276563636 1e-09 0.573743072 0.000000001 0.311695728 #>  #> $Loss #> [1] -0.7595456 -0.7074246 #>  #> $Iterations #> [1] 20 #>"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_svi.html","id":null,"dir":"Reference","previous_headings":"","what":"Use SVI algorithm to fit PSD model — psd_fit_svi","title":"Use SVI algorithm to fit PSD model — psd_fit_svi","text":"Fit PSD model SVI algorithm, use loss function stopping criterion.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_svi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use SVI algorithm to fit PSD model — psd_fit_svi","text":"","code":"psd_fit_svi(   G,   K,   epsilon = 1e-05,   maxiter = 5e+05,   val_iter = 10000,   maxdrop = 3,   maxiter.sample = 100,   maxiter.val = 2000,   val_J = 0.05,   val_I = 0.1,   tau = 1,   kappa = 0.5 )"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_svi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use SVI algorithm to fit PSD model — psd_fit_svi","text":"G x J matrix counts; entries G taken {0,1,2}. K integer 2 greater giving matrix rank. epsilon Convergence criterion. maxiter maximum number iterations. val_iter number iterations validation set sampling. maxdrop maximum number consecutive decreases loss function. Beyond value loop stop. maxiter.sample maximum number iterations sampling section. maxiter.val maximum number iterations validation section. val_J Sample proportion SNPs validation set. val_I Sample proportion individuals validation set. tau parameter descending direction SVI algorithm. kappa parameter descending direction SVI algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_svi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use SVI algorithm to fit PSD model — psd_fit_svi","text":"List following parameters: P population scale matrix individuals. Loss vector represents value loss function records 10 iterations. MaxLoss Maximum loss function value. Unlike algorithms, observe loss function validation set. Therefore, monotonicity guaranteed, , maximum value necessarily occur end, maximum value needs recorded. Iterations integer represents number iterations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_svi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use SVI algorithm to fit PSD model — psd_fit_svi","text":"","code":"# Refer to Articles in AwesomePackage."},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_vi.html","id":null,"dir":"Reference","previous_headings":"","what":"Use VI algorithm to fit PSD model — psd_fit_vi","title":"Use VI algorithm to fit PSD model — psd_fit_vi","text":"Fit PSD model VI algorithm, use loss function stopping criterion.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_vi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use VI algorithm to fit PSD model — psd_fit_vi","text":"","code":"psd_fit_vi(G, K, epsilon = 1e-05, maxiter = 500)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_vi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use VI algorithm to fit PSD model — psd_fit_vi","text":"G x J matrix counts; entries G taken {0,1,2}. K integer 2 greater giving matrix rank. epsilon Convergence criterion. maxiter maximum number iterations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_vi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use VI algorithm to fit PSD model — psd_fit_vi","text":"List following parameters: P population scale matrix individuals. F gene scale matrix populations. Loss vector represents value loss function records 10 iterations. Iterations integer represents number iterations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_fit_vi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use VI algorithm to fit PSD model — psd_fit_vi","text":"","code":"G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) psd_fit_vi(G, 2, 1e-5, 10) #> $P #>           [,1]      [,2] #> [1,] 0.6126433 0.3873567 #> [2,] 0.3363156 0.6636844 #> [3,] 0.4785760 0.5214240 #>  #> $F #>           [,1]      [,2]      [,3]      [,4]      [,5] #> [1,] 0.3064798 0.3920361 0.4563244 0.2652133 0.3508395 #> [2,] 0.2939170 0.6020971 0.3475661 0.3334554 0.2535043 #>  #> $Loss #> [1] -1.772244 #>  #> $Iterations #> [1] 10 #>"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the loglikelihood — psd_loglikelihood","title":"Compute the loglikelihood — psd_loglikelihood","text":"Compute maximum loglikelihood function PSD model.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the loglikelihood — psd_loglikelihood","text":"","code":"psd_loglikelihood(G, result)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the loglikelihood — psd_loglikelihood","text":"G x J matrix counts; entries G taken {0,1,2}. result Output psd_fit_em, psd_fit_sqp, psd_fit_vi.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the loglikelihood — psd_loglikelihood","text":"value indicates accuracy prediction.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the loglikelihood — psd_loglikelihood","text":"","code":"G <- matrix(c(0,0,1, 0,2,1, 1,0,1, 0,1,0, 1,0,0), 3, 5) result <- psd_fit_em(G, 2, 1e-5, 10) psd_loglikelihood(G, result) #> [1] -0.7338385"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood_svi.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the loglikelihood of svi method in validation set — psd_loglikelihood_svi","title":"Compute the loglikelihood of svi method in validation set — psd_loglikelihood_svi","text":"Compute maximum loglikelihood function PSD model validation set using svi method.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood_svi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the loglikelihood of svi method in validation set — psd_loglikelihood_svi","text":"","code":"psd_loglikelihood_svi(G, K, P, maxiter = 2000)"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood_svi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the loglikelihood of svi method in validation set — psd_loglikelihood_svi","text":"G x J matrix counts; entries G taken {0,1,2}. K integer 2 greater giving matrix rank. P P output list psd_fit_svi. maxiter maximum number iterations validation set.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood_svi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the loglikelihood of svi method in validation set — psd_loglikelihood_svi","text":"value indicates accuracy prediction validation set.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_loglikelihood_svi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the loglikelihood of svi method in validation set — psd_loglikelihood_svi","text":"","code":"# Refer to Articles in AwesomePackage."},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_simulation.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data of PSD model — psd_simulation","title":"Simulate data of PSD model — psd_simulation","text":"Simulate gene data PSD model including P, F, G.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_simulation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data of PSD model — psd_simulation","text":"","code":"psd_simulation(   I,   J,   K,   type.id = c(\"A\", \"B\"),   parm_alpha = 0.1,   parm_sd = 2,   parm_F = NULL,   data = data_HGDP )"},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_simulation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data of PSD model — psd_simulation","text":"number individuals simulate. J number SNPs simulate. K number populations simulate. type.id Choose type. one \"\", \"B\". parm_alpha parameter normal distribution simulation first type P. parm_sd parameter normal distribution simulation second type P. parm_F parameter beta distribution simulation F. length K. data data needed provided order collect suballele frequencies real SNPs simulation F.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_simulation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data of PSD model — psd_simulation","text":"List following parameters: G x J simulated matrix counts. P x K simulated population scale matrix individuals. F K x J simulated gene scale matrix populations.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/reference/psd_simulation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data of PSD model — psd_simulation","text":"","code":"data_simuA <- psd_simulation(60, 250, 3, type.id = \"A\", parm_F = c(0.1, 0.05, 0.01)) plot_structure(data_simuA$P, pops = rep(3:1))  data_simuB <- psd_simulation(100, 500, 5, type.id = \"B\") plot_structure(data_simuB$P, pops = rep(5:1))"},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-200","dir":"Changelog","previous_headings":"","what":"AwesomePackage 2.0.0","title":"AwesomePackage 2.0.0","text":"Completed major release comprehensive updates package.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-190","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.9.0","title":"AwesomePackage 1.9.0","text":"Updated vignettes.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-180","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.8.0","title":"AwesomePackage 1.8.0","text":"Added logo. Updated vignettes.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-170","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.7.0","title":"AwesomePackage 1.7.0","text":"Changed entire appearance website using Bootswatch theme.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-160","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.6.0","title":"AwesomePackage 1.6.0","text":"Added vignettes.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-150","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.5.0","title":"AwesomePackage 1.5.0","text":"Added vignettes. Updated code draw structure diagram.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-140","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.4.0","title":"AwesomePackage 1.4.0","text":"Added code generate simulated data. Added vignettes.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-130","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.3.0","title":"AwesomePackage 1.3.0","text":"Added NEWS.md file track changes package. Updated vignettes.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-120","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.2.0","title":"AwesomePackage 1.2.0","text":"Added code log-likelihood function validation set. Added vignettes.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-110","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.1.0","title":"AwesomePackage 1.1.0","text":"Added R.rsp weave static PDF vignettes. Updated website pkgdown.extras based pkgdown.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-100","dir":"Changelog","previous_headings":"","what":"AwesomePackage 1.0.0","title":"AwesomePackage 1.0.0","text":"Pushed docs folder GitHub.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-090","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.9.0","title":"AwesomePackage 0.9.0","text":"Added code draw diagram relationship index K. Updated code implement EM, SQP, VI SVI algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-080","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.8.0","title":"AwesomePackage 0.8.0","text":"Added HGDP data set. Added MAP files TGP data set HGDP data set. Added code log-likelihood function error function. Updated code draw structure diagram.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-070","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.7.0","title":"AwesomePackage 0.7.0","text":"Added code implement SVI algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-060","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.6.0","title":"AwesomePackage 0.6.0","text":"Added code draw loss curve.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-050","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.5.0","title":"AwesomePackage 0.5.0","text":"Added code implement VI algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-040","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.4.0","title":"AwesomePackage 0.4.0","text":"Added TGP data set.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-030","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.3.0","title":"AwesomePackage 0.3.0","text":"Updated code implement SQP algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-020","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.2.0","title":"AwesomePackage 0.2.0","text":"Added code implement SQP algorithm.","code":""},{"path":"https://jonathonchow.github.io/AwesomePackage/news/index.html","id":"awesomepackage-010","dir":"Changelog","previous_headings":"","what":"AwesomePackage 0.1.0","title":"AwesomePackage 0.1.0","text":"Added code implement EM algorithm. Added code draw structure diagram.","code":""}]
